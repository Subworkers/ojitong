{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리, API 접속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.22)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.1.52)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.1.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain) (1.10.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m980.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-inspect, multidict, marshmallow, frozenlist, yarl, dataclasses-json, aiosignal, aiohttp, langchain-text-splitters, langchain-community, langchain\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 dataclasses-json-0.6.6 frozenlist-1.4.1 langchain-0.1.20 langchain-community-0.0.38 langchain-text-splitters-0.0.1 marshmallow-3.21.2 multidict-6.0.5 typing-inspect-0.9.0 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (1.30.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.10.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.46 (from langchain_openai)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting openai<2.0.0,>=1.24.0 (from langchain_openai)\n",
      "  Downloading openai-1.30.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
      "  Downloading langsmith-0.1.57-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.10.2)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.0.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.8.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.5.2->langchain_openai)\n",
      "  Downloading regex-2024.5.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m963.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.28.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.4)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
      "  Downloading orjson-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (1.26.12)\n",
      "Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
      "Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.57-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.2/785.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading orjson-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, regex, orjson, httpcore, distro, tiktoken, langsmith, httpx, openai, langchain-core, langchain_openai\n",
      "Successfully installed distro-1.9.0 httpcore-1.0.5 httpx-0.27.0 langchain-core-0.1.52 langchain_openai-0.1.6 langsmith-0.1.57 openai-1.30.1 orjson-3.10.3 regex-2024.5.10 tenacity-8.3.0 tiktoken-0.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#템플릿 생성 - 채팅 프롬프트 템플릿\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# 환경변수에 OpenAI API 키 저장 (사용자 입력으로 안전하게)\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# GPT-4 모델로 챗봇 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3가지 프롬프트로 구분\n",
    "1. 글구조 프롬프트\n",
    "2. 글 생성 프롬프트\n",
    "3. 글 평가 프롬프트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.글 구조 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_benchmark=\"\"\"안녕하세요, 여러분의 출퇴근 메신저 지하철 온다의 '오.지.통 [오늘의 지하철 소식통]' 인사 드립니다!\n",
    "지하철 이용객 여러분, 서울 지하철 경고파업에 대한 중요한 업데이트가 있습니다.\n",
    "​\n",
    "파업 일정\n",
    "\n",
    "파업 일시: 2023년 11월 9일부터 11월 10일까지\n",
    "\n",
    "파업 노선: 서울지하철 1∼8호선, 9호선 2·3단계 구간(신논현∼중앙보훈병원역)\n",
    "\n",
    "파업 이유: 임금 및 단체협약 협상 결렬, 인력 감축 및 안전 업무 외주화 철회 요구\n",
    "\n",
    "문의 사항: 서울교통공사 홈페이지\n",
    "\n",
    "​\n",
    "\n",
    "\n",
    "서울 지하철에서 열리는 경고파업 소식, 여러분도 들으셨나요?\n",
    "\n",
    "서울의 지하철 노선들이 11월 9일부터 10일까지 파업을 예정하고 있어요.\n",
    "\n",
    "아침저녁 출퇴근길이 조금 힘들어질 수 있으니, 저와 함께 대비책을 세워봐요!\n",
    "\n",
    "파업 기간 중 대응 방법과 출근길 준비 전략\n",
    "\n",
    "시간대별 지하철 정보 챙기기\n",
    "\n",
    "파업 동안은 지하철 운행이 조금씩 달라질 수 있어요.\n",
    "\n",
    "집을 나서기 전에 미리 체크하고 시간을 조정해보세요!\n",
    "\n",
    "​\n",
    "\n",
    "대체 교통수단 적극 활용하기\n",
    "\n",
    "버스가 아침 7시부터 9시, 저녁 6시부터 8시까지 집중 배차된다고 하니,\n",
    "\n",
    "버스로 갈아타는 것도 좋은 선택이 될 수 있어요.\n",
    "\n",
    "​\n",
    "\n",
    "비상 연락망 활용하기\n",
    "\n",
    "파업 기간 중에는 유연하게 근무하거나 수업에 참여할 수 있도록 회사나 학교와 연락해 조율해 보세요.\n",
    "\n",
    "​\n",
    "\n",
    "비록 지하철이 잠시 멈춰 서도 우리의 출퇴근은 멈출 수 없잖아요!\n",
    "\n",
    "서울교통공사와 서울시가 불편을 최소화하기 위해 노력 중이니,\n",
    "\n",
    "조금만 참고 우리 모두 함께 이 어려운 시기를 잘 넘겨봐요.\n",
    "\n",
    "​\n",
    "\n",
    "오지통과 함께라면 출퇴근도 즐거워질 수 있어요, 자주 들러서 최신 소식도 확인하고 힘내세요!\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "'지하철 온다'는 단 한 번의 터치로\n",
    "\n",
    "자신의 위치에서 가장 가까운 지하철역의\n",
    "\n",
    "실시간 도착 정보를 제공합니다\n",
    "\n",
    "​\n",
    "\n",
    "🔽 지하철 온다 소개 보러가기\n",
    "\n",
    "https://blog.naver.com/subway__onda/223258646349\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the table of structure from the provided text in English. Please don't give me the details of the structure of the article JUST STRUCTURE 1: Greeting 2:\"), #\"목차정보 추출\"\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain= prompt1|llm\n",
    "Structure=chain.invoke({\"input\":page_benchmark})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1: Greeting\\n2: Strike Update Announcement\\n3: Strike Details\\n4: Additional Explanatory Information\\n5: Strike Preparedness Suggestions\\n6: Encouragement and Conclusion\\n7: App Advertisement'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Structure.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#글 구조 리스트로 변형 (task 쪼개기 위함)\n",
    "import re\n",
    "#글의 구조에서 너무 자세한 정보는 직접 제거하였음.\n",
    "output1 = '1: Greeting\\n2: Strike Update Announcement\\n3: Strike Details\\n4: Additional Explanatory Information\\n5: Strike Preparedness Suggestions\\n6: Encouragement and Conclusion\\n7: App Advertisement'\n",
    "# Using regex to split the string into sections starting with number and period\n",
    "sections = re.split(r'\\n(?=\\d+\\.)', output1)\n",
    "section=\"\"\n",
    "for i in (sections):\n",
    "          section+=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1: Greeting\\n2: Strike Update Announcement\\n3: Strike Details\\n4: Additional Explanatory Information\\n5: Strike Preparedness Suggestions\\n6: Encouragement and Conclusion\\n7: App Advertisement'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 글 생성 프롬프트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### source 기사 (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_link=\"https://www.sedaily.com/NewsView/29X8F079IZ\"\n",
    "source_content=\"\"\"\"또 퇴근길 대란 일어나나\"…22일 서울지하철 2차 총파업 예고\n",
    "인력감축 놓고 노사 합의점 못찾아\n",
    "\n",
    "황정원 기자2023-11-14 17:57:36사회일반\n",
    "'또 퇴근길 대란 일어나나'…22일 서울지하철 2차 총파업 예고\n",
    "서울교통공사 노조 파업 이틀째인 10일 오전 서울 지하철 광화문역에서 시민들이 열차에서 내리고 있다. 연합뉴\n",
    "\n",
    "\n",
    "서울지하철 1∼8호선을 운영하는 서울교통공사 노동조합이 22일 2차 총파업을 예고했다.\n",
    "\n",
    "\n",
    "민주노총 공공운수노조 산하 서울교통공사노조는 15일 오전 10시 서울시청 앞에서 “안전업무 외주화 저지, 현장 안전인력 공백 대책 수립”을 요구하는 기자회견을 열고 2차 파업 계획을 공개할 예정이라고 14일 밝혔다. 파업 예정일은 22일로 알려졌다.\n",
    "\n",
    "\n",
    "노조는 사측의 대규모 인력감축안 등에 반발해 지난 9~10일 이틀간 시한부 경고 파업을 벌였다. 이후 노사 실무자 간 대화를 이어가고는 있으나 아직 합의점을 찾지는 못했다.\n",
    "\n",
    "\n",
    "노조는 \"1차 경고 파업 이후 지속적으로 서울시와 공사 측에 입장 변화와 진지한 대화를 촉구했지만, 서울시와 공사는 갑자기 강력 대응 기조로 돌변했다\"며 \"현장 안전인력 공백 우려에 대한 어떤 대책도 제시하지 않고 있다\"고 밝혔다. 노조는 기자회견에서 자세한 파업 계획과 향후 일정을 밝힐 예정이다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 글생성 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The system utilizes the structure from existing blog benchmark articles and creates new blog posts using information from new source data.\n",
      "          structure from existing blog benchmark articles : 1: Greeting\n",
      "2: Strike Update Announcement\n",
      "3: Strike Details\n",
      "4: Additional Explanatory Information\n",
      "5: Strike Preparedness Suggestions\n",
      "6: Encouragement and Conclusion\n",
      "7: App Advertisement\n",
      "          Once you obtain information from the source data, you will write the article considering the structure from existing blog benchmark articles.\n",
      "          \n",
      "Human: source data:{\"또 퇴근길 대란 일어나나\"…22일 서울지하철 2차 총파업 예고\n",
      "인력감축 놓고 노사 합의점 못찾아\n",
      "\n",
      "황정원 기자2023-11-14 17:57:36사회일반\n",
      "'또 퇴근길 대란 일어나나'…22일 서울지하철 2차 총파업 예고\n",
      "서울교통공사 노조 파업 이틀째인 10일 오전 서울 지하철 광화문역에서 시민들이 열차에서 내리고 있다. 연합뉴\n",
      "\n",
      "\n",
      "서울지하철 1∼8호선을 운영하는 서울교통공사 노동조합이 22일 2차 총파업을 예고했다.\n",
      "\n",
      "\n",
      "민주노총 공공운수노조 산하 서울교통공사노조는 15일 오전 10시 서울시청 앞에서 “안전업무 외주화 저지, 현장 안전인력 공백 대책 수립”을 요구하는 기자회견을 열고 2차 파업 계획을 공개할 예정이라고 14일 밝혔다. 파업 예정일은 22일로 알려졌다.\n",
      "\n",
      "\n",
      "노조는 사측의 대규모 인력감축안 등에 반발해 지난 9~10일 이틀간 시한부 경고 파업을 벌였다. 이후 노사 실무자 간 대화를 이어가고는 있으나 아직 합의점을 찾지는 못했다.\n",
      "\n",
      "\n",
      "노조는 \"1차 경고 파업 이후 지속적으로 서울시와 공사 측에 입장 변화와 진지한 대화를 촉구했지만, 서울시와 공사는 갑자기 강력 대응 기조로 돌변했다\"며 \"현장 안전인력 공백 우려에 대한 어떤 대책도 제시하지 않고 있다\"고 밝혔다. 노조는 기자회견에서 자세한 파업 계획과 향후 일정을 밝힐 예정이다.\n",
      "}Do not start writing until you are given a command. Just Review source data\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The system utilizes the structure from existing blog benchmark articles and creates new blog posts using information from new source data.\n",
      "          structure from existing blog benchmark articles : 1: Greeting\n",
      "2: Strike Update Announcement\n",
      "3: Strike Details\n",
      "4: Additional Explanatory Information\n",
      "5: Strike Preparedness Suggestions\n",
      "6: Encouragement and Conclusion\n",
      "7: App Advertisement\n",
      "          Once you obtain information from the source data, you will write the article considering the structure from existing blog benchmark articles.\n",
      "          \n",
      "System: The Seoul Subway labor union has announced a second general strike for November 22, protesting against staff reductions and outsourcing of safety tasks, with no resolution reached between the union and management despite previous strikes and ongoing discussions.\n",
      "Human: 1: Greeting\n",
      "2: Strike Update Announcement\n",
      "3: Strike Details\n",
      "4: Additional Explanatory Information\n",
      "5: Strike Preparedness Suggestions\n",
      "6: Encouragement and Conclusion\n",
      "7: App Advertisement\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The system utilizes the structure from existing blog benchmark articles and creates new blog posts using information from new source data.\n",
      "          structure from existing blog benchmark articles : 1: Greeting\n",
      "2: Strike Update Announcement\n",
      "3: Strike Details\n",
      "4: Additional Explanatory Information\n",
      "5: Strike Preparedness Suggestions\n",
      "6: Encouragement and Conclusion\n",
      "7: App Advertisement\n",
      "          Once you obtain information from the source data, you will write the article considering the structure from existing blog benchmark articles.\n",
      "          \n",
      "System: The Seoul Subway labor union has announced a second general strike for November 22, protesting against staff reductions and outsourcing of safety tasks, with no resolution reached between the union and management despite previous strikes and ongoing discussions. The union emphasizes that these changes could compromise safety and efficiency, urging the need for adequate staffing and direct management of safety measures. Commuters are advised to seek alternative transportation options and stay updated through local news and official channels. The 'City Transit Helper' app is recommended for real-time updates and travel planning during the strike.\n",
      "Human: Translate English to Korean\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The system utilizes the structure from existing blog benchmark articles and creates new blog posts using information from new source data.\n",
      "          structure from existing blog benchmark articles : 1: Greeting\n",
      "2: Strike Update Announcement\n",
      "3: Strike Details\n",
      "4: Additional Explanatory Information\n",
      "5: Strike Preparedness Suggestions\n",
      "6: Encouragement and Conclusion\n",
      "7: App Advertisement\n",
      "          Once you obtain information from the source data, you will write the article considering the structure from existing blog benchmark articles.\n",
      "          \n",
      "System: The Seoul Subway labor union has announced a second general strike for November 22, protesting against staff reductions and outsourcing of safety tasks, with no resolution reached between the union and management despite previous strikes and ongoing discussions. The union emphasizes that these changes could compromise safety and efficiency, urging the need for adequate staffing and direct management of safety measures. Commuters are advised to seek alternative transportation options and stay updated through local news and official channels. The 'City Transit Helper' app is recommended for real-time updates and travel planning during the strike. The announcement and details of the strike have also been translated into Korean for broader accessibility.\n",
      "Human: 대학생서포터즈가 작성한 것 처럼 통통 튀게 작성해줘.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "messages=[\n",
    "SystemMessagePromptTemplate.from_template(\n",
    "          \"\"\"The system utilizes the structure from existing blog benchmark articles and creates new blog posts using information from new source data.\n",
    "          structure from existing blog benchmark articles : \"\"\"+section+\"\"\"\n",
    "          Once you obtain information from the source data, you will write the article considering the structure from existing blog benchmark articles.\n",
    "          \"\"\"\n",
    "),\n",
    "# The `variable_name` here is what must align with memory\n",
    "MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100,memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(\n",
    "llm=llm,\n",
    "prompt=prompt,\n",
    "verbose=True,\n",
    "memory=memory\n",
    ")\n",
    "\n",
    "conversation({\"question\":'source data:{'+source_content +'}Do not start writing until you are given a command. Just Review source data'})\n",
    "content=\"\"\n",
    "for j in sections:\n",
    "          content+=conversation.predict(question=j)\n",
    "#시스템프롬프트수정 - 번역 & 대학생서포터즈\n",
    "conversation.predict(question=\"Translate English to Korean\")\n",
    "result=conversation.predict(question=\"대학생서포터즈가 작성한 것 처럼 통통 튀게 작성해줘.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"안녕하세요, 여러분! 서울 지하철에서 또 다시 소식이 전해졌습니다! 이번에는 노조가 11월 22일에 두 번째 파업을 예고했어요. 이유를 들어보니, 직원 감축과 안전 업무의 외주화에 대한 반대라고 하네요. 이전 파업과 논의에도 불구하고 아직 해결책을 찾지 못했다고 해요.\\n\\n노조 측은 이런 변화가 안전성과 효율성을 위협할 수 있다며, 적절한 인력 배치와 안전 관리의 직접 수행을 강조하고 있어요. 이에 따라, 파업 날짜에는 서울 지하철 이용에 차질이 예상되니, 대중교통 이용자 여러분들은 미리 다른 교통 수단을 찾아보시는 게 좋겠어요.\\n\\n그리고, 파업 도중에는 실시간 교통 업데이트와 여행 계획을 도와줄 수 있는 'City Transit Helper' 앱 사용을 추천드립니다. 이 앱은 파업 상황에서도 여러분이 원활하게 목적지까지 이동할 수 있도록 도와줄 거예요.\\n\\n노조의 발표와 파업 세부사항은 한국어로도 번역되어 더 많은 사람들이 접근할 수 있도록 했으니, 관련 소식은 꼭 확인해보세요.\\n\\n여러분, 이번 파업 기간 동안 불편함을 최소화할 수 있도록 미리 준비하시고, 언제나 안전 운전하세요! 파업이 빨리 해결되어 일상이 원활하게 돌아가길 바랍니다. 여러분의 끈기와 협력이 필요한 시기입니다. 함께 힘내요! 😊\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.글 평가 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리스트 생성\n",
    "consistency=[]\n",
    "coherence=[]\n",
    "friendliness=[]\n",
    "fluency=[]\n",
    "humanlikeness=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 평가 방법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=[\"\"\"Compare and evaluate the blog content you created with the article.\n",
    "First, Extract the key information from the article. (time,date,subway line)\n",
    "You need to decide whether the key information is entailed by the  CONTEXT by choosing one of the following rating: \n",
    "\n",
    "1. 5 point: The blog content follows logically from the information contained in the article. \n",
    "\n",
    "2. 1 point: The blog content is logically false from the information contained in the article. \n",
    "\n",
    "3. an integer score between 1 and 5 and if such integer score does not exist,  \n",
    "\n",
    "use 1: It is not possible to determine whether the blog content is true or false without further information. \n",
    "\n",
    "Read the passage of information thoroughly and select the correct answer from the three answer labels. \n",
    "\n",
    "Read the CONTEXT thoroughly to ensure you know what the CONTEXT entails.  \n",
    "\n",
    "Note the blog content is generated by a computer system, it can contain certain symbols, which should not be a negative factor in the evaluation.\n",
    "\n",
    "\n",
    "Evaluation Form (scores ONLY):\n",
    "\n",
    "- Consistency:\n",
    "          \n",
    "          \"\"\",\n",
    "\"\"\"Your task is to rate the blog content on one metric.\n",
    "\n",
    "          Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
    "\n",
    "          Evaluation Criteria:\n",
    "\n",
    "          Coherence (1-5) - the collective quality of all sentences. We align this dimension with the DUC quality question of structure and coherence whereby \"the summary should be well-structured and well-organized. The summary should not just be a heap of related information, but should build from sentence to a coherent body of information about a topic.\"\n",
    "\n",
    "          Evaluation Steps:\n",
    "\n",
    "          1. Read the news article carefully and identify the main topic and key points.\n",
    "          2. Read the blog content and compare it to the news article. Check if the summary covers the main topic and key points of the news article, and if it presents them in a clear and logical order.\n",
    "          3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n",
    "\n",
    "\n",
    "\n",
    "          Evaluation Form (scores ONLY):\n",
    "\n",
    "          - Coherence:\n",
    "          \n",
    "          \"\"\",\n",
    "\"\"\"Friendliness, as a metric, measures how effectively the text of a blog content engages the reader with a friendly and inviting tone. If the tone and style of the text foster a sense of warmth and familiarity, making the reader feel welcomed and engaged, then the value of the Friendliness metric should be high; otherwise, it should be low. After reading the blog post, evaluate its tone and style against typical friendly communication, and determine the value of the Friendliness metric using the following rating scale:\n",
    "\n",
    "          - One star: The tone is cold or unfriendly, not engaging the reader in any appreciable way.\n",
    "          - Two stars: The tone has minimal warmth, slightly engaging but largely formal or distant.\n",
    "          - Three stars: The tone is moderately friendly, balancing formal and informal elements to somewhat engage the reader.\n",
    "          - Four stars: The tone is very friendly, actively engaging the reader with warmth and lively expressions.\n",
    "          - Five stars: The tone is exceptionally friendly and lively, creating a strong sense of connection and engagement with the reader.\n",
    "\n",
    "          This rating should always be an integer between 1 and 5. Thus, the rating produced should be 1, 2, 3, 4, or 5, based on your assessment of how friendly and engaging the text is towards the read.\n",
    "\n",
    "          Evaluation Template (Score Only):\n",
    "\n",
    "          Friendliness:\n",
    "          \"\"\",\n",
    "\"\"\"Fluency measures the quality of individual sentences in the answer, and whether they are well-written and grammatically correct. Consider the quality of individual sentences when evaluating fluency. Given the question and answer, score the fluency of the answer between one to five stars using the following rating scale: \n",
    "\n",
    "          One star: the answer completely lacks fluency \n",
    "\n",
    "          Two stars: the answer mostly lacks fluency \n",
    "\n",
    "          Three stars: the answer is partially fluent \n",
    "\n",
    "          Four stars: the answer is mostly fluent \n",
    "\n",
    "          Five stars: the answer has perfect fluency \n",
    "\n",
    "          This rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.\n",
    "\n",
    "\n",
    "          Evaluation Template (Score Only):\n",
    "\n",
    "          Fluency:\n",
    "          \"\"\",\n",
    "\"\"\"Human-likeness, as a metric, evaluates how closely the style and delivery of GPT-generated text resemble that of naturally written human text. If the text is indistinguishable from human writing in terms of natural flow, vocabulary use, and contextual accuracy, then the value of the Human-likeness metric should be high; otherwise, it should be low. Given the text generated by GPT and comparing it to typical human-written text, determine the value of the Human-likeness metric using the following rating scale:\n",
    "\n",
    "          - One star: The text is entirely machine-like, with unnatural flow and numerous contextual errors.\n",
    "          - Two stars: The text is mostly machine-like, with frequent unnatural expressions and noticeable errors.\n",
    "          - Three stars: The text is somewhat human-like, showing signs of natural language use but with some mechanical characteristics.\n",
    "          - Four stars: The text is mostly human-like, with very few mechanical traits and generally natural language use.\n",
    "          - Five stars: The text is completely human-like, indistinguishable from something a human might write.\n",
    "\n",
    "          This rating should always be an integer between 1 and 5. Thus, the rating produced should be 1, 2, 3, 4, or 5, based on the evaluation.\n",
    "          \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 평가 시작 (평가에서는 각각의 새로운 채팅으로 하였음) -> memory 사용x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정확성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "#정확성- 기사(source)와 블로그 콘텐츠 모두 넣어야함\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", eval[0]),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain = prompt | llm | output_parser\n",
    "consistency+=[chain.invoke({\"input\": \"blog content:\"+result+\"article, source:\"+source_content})]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", eval[1]),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain=prompt|llm|output_parser\n",
    "coherence+=[chain.invoke({\"input\": \"blog content:\"+result})]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friendliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", eval[2]),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain=prompt|llm|output_parser\n",
    "friendliness+=[chain.invoke({\"input\": \"blog content:\"+result})]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fluency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", eval[3]),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain=prompt|llm|output_parser\n",
    "fluency+=[chain.invoke({\"input\": \"blog content:\"+result})]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human-likeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", eval[4]),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain=prompt|llm|output_parser\n",
    "humanlikeness+=[chain.invoke({\"input\": \"blog content:\"+result})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,pd.DataFrame({\"link\":[source_link],\"source\":[source_content],\"result\":[result],\"consistency\":[consistency],\"coherence\":[coherence],\"friendliness\":[friendliness],\"human_likeness\":[humanlikeness]})])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fianl_result_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
