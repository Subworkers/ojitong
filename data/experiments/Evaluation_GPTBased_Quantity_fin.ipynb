{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **🎯 GPT 기반 정량평가 : : QG-QA**\n",
        "## **📍문제 정의**\n",
        "- 뉴스 기사 각각에 대해 LLM을 적용하여 기사에 대한 블로그 글을 만든 상황에서,\n",
        "- 블로그 글이 뉴스 기사의 내용을 잘 담고 있는지 QG-QA를 통해 평가하고자 한다.\n",
        "- 사용 모델: **gpt-4o**\n",
        "\n",
        "## **📍수행 과정**\n",
        "1. **뉴스 기사와 그에 대응하는 블로그 글에 대해 동일한 질문을 생성**\n",
        "  - OUTPUT 이 질문 리스트가 되도록 PROMPT 구성하기\n",
        "2. **뉴스 기사, 블로그 글에 질문 각각 ASK**\n",
        "3. **그에 대한 답변이 서로 일치하는지 확인한다.**\n",
        "  - 두 답변을 서로 비교하여 일치할 경우 True(1), 아닐 경우 False(0) 반환\n",
        "\n",
        "## **📍선택지**\n",
        "1. **한번에 한개의 질문만 / 한번에 여러개의 질문?** → *여러개의 질문*\n",
        "2. **페르소나 1개로 통일/질문답변 페르소나 2개로 분리?** → *2개*\n",
        "3. **메모리 사용/미사용?** → *미사용*\n",
        "\n",
        "## **📍기타사항**\n",
        "1. 질문 2개로 축소(사건 발생 원인은 다른 질문에 비해 중요성과 정확성이 낮아 제거함)\n",
        "2. 질문마다 5개의 선지, '알 수 없음; 선지는 무조건 포함\n",
        "3. QG와 QA단계 모두에 Step 을 지정함\n",
        "4. gpt-4-turbo 대신 gpt-4o 사용 - 비용 절감\n",
        "5. ***🚨해당 함수에 뉴스와 블로그 데이터를 주입할 때 '반드시' 뉴스는 제목, 발행일자, 본문이 분리된 상태일 것***\n",
        "\n",
        "## **📍진행 순서**\n",
        "\n",
        "        * (1) 입력 - 뉴스 제목, 뉴스 본문, 뉴스 날짜, 블로그 텍스트 → news_sample, blog_sample\n",
        "        * (2) RPOMPT1 - 뉴스기사를 기반으로 질문을 만들어줘- 질문 도출\n",
        "        * (3) PROMPT2 - 뉴스 기사에 대해 질문의 답변 도출\n",
        "        * (4) PROMPT3 - 블로그 글에 대해 질문의 답변 도출\n",
        "        * (5)일치여부판단 - (3), (4)의 결과로 나온 답변을 비교"
      ],
      "metadata": {
        "id": "OQzY3pSslLA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📍1. 환경세팅**"
      ],
      "metadata": {
        "id": "f9IJJxwrlaWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "!pip install langchain\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4KSo5ydlfKk",
        "outputId": "4341ab8f-eff4-4d43-bd54-3c163496f85f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.63-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.1 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langsmith-0.1.63 orjson-3.10.3 packaging-23.2\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.30.3)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (0.1.63)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain_openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.1.7 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "# 환경변수에 OpenAI API 키 저장 (사용자 입력으로 안전하게)\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAIFMWfjlnNa",
        "outputId": "d602b3ec-8cc4-442f-a1c7-83fe79184462"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4 챗봇 객체 생성\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# 프롬프트 템플릿, 파서를 각각 생성한 뒤 챗봇과 체인 결합\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# PROMPT1 - 뉴스 기반으로 질문 생성 - chain_1으로 생성\n",
        "prompt_1 = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an AI trained to generate insightful questions from a given article.\"\"\"), # 페르소나 부여\n",
        "    (\"user\", \"\"\"\n",
        "    1. Read the article about current Seoul subway news.\n",
        "    2. Find out what is the main incident related with subway in the article.\n",
        "    3. Find the date that this article was issued\n",
        "    4. Find every date-related expression in the article.\n",
        "    5. Compare 3 and 4, and find out the date the incident was occured.\n",
        "    6. Find every expression related to line of subway in the article.\n",
        "    7. Find out which line the incident is about.\n",
        "    8. Create 2 questions to identify the main points of the news (date of the incident, subway line of the incident). The questions should be 5-way multiple choice questions where you have to choose one of the choices from 1 to 5. One of the options must be “Unknown” and the selection for the “Date of Event” question must be in the format 2018년 3월 18일. Hint is provided with every questions\n",
        "\n",
        "    <Example Question>: 'Where did the subway incident occur? (1) Gangnam Station (2) Seongsu Station (3) Suyu Station (4) Ankguk Station (5) Unknown)',\n",
        "    <Example Hint>:''\n",
        "    News Article= {input}\n",
        "    \"\"\"),\n",
        "    (\"system\", \"\"\"Generate 2 questions. All should be in Korean ONLY.\n",
        "\n",
        "Template:\n",
        "Question1: {{}},\n",
        "Hint1: {{}},\n",
        "Question2: {{}},\n",
        "Hint2: {{}}\"\"\")\n",
        "])\n",
        "chain_1 = prompt_1 | llm | output_parser\n",
        "\n",
        "# PROMPT2 입력 - 뉴스 기사에 대해 질문의 답변 도출 - chain_2으로 생성\n",
        "prompt_2 = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You read a news article and answer a question accurately based on what you read.\"\"\"), # 페르소나 부여\n",
        "    (\"user\", \"\"\"\n",
        "    You read a news article like this:\n",
        "    1. Read the article about current Seoul subway news.\n",
        "    2. Find out what is the main incident related with subway in the article.\n",
        "    3. Find the date that this article was issued\n",
        "    4. Find every date-related expression in the article.\n",
        "    5. Compare 3 and 4, and find out the date the incident was occured.\n",
        "    6. Find every expression related to line of subway in the article.\n",
        "    7. Find out which line the incident is about.\n",
        "    Then you answer a question accurately based on what you read.\n",
        "    Example= “1번, 5번, 4번”,\n",
        "    news= {input}\n",
        "    Questions= {question}\n",
        "    \"\"\"),\n",
        "    (\"system\", \"\"\"\"Template(MUST FOLLOW): Answer1: {{answer_1}}번, Answer2: {{answer_2}}번\"\"\")\n",
        "])\n",
        "chain_2 = prompt_2 | llm | output_parser\n",
        "\n",
        "# PROMPT3 입력 - 블로그글에 대해 질문의 답변 도출 - chain_3으로 생성\n",
        "prompt_3 = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You read a blog article and answer a question accurately based on what you read\"\"\"), # 페르소나 부여\n",
        "    (\"user\", \"\"\"\n",
        "    You read a blog article like this:\n",
        "    1. Read the blog about current Seoul subway news.\n",
        "    2. Find out what is the main incident related with subway in the article.\n",
        "    3. Find every date-related expression in the article.\n",
        "    4. Find out the date the incident was occured.\n",
        "    5. Find every expression related to line of subway in the article.\n",
        "    6. Find out which line the incident is about.\n",
        "    Then you answer 2 questions accurately based on what you read.\n",
        "    Example= “1번, 5번, 4번”,\n",
        "    blog= {input}\n",
        "    Questions= {question}\n",
        "    \"\"\"),\n",
        "    (\"system\", \"\"\"Template(MUST FOLLOW): Answer1: {{answer_1}}번, Answer2: {{answer_2}}번\"\"\")\n",
        "])\n",
        "chain_3 = prompt_3 | llm | output_parser\n",
        "\n",
        "\n",
        "\n",
        "def quan_eval(title, date, article, blog):\n",
        "\n",
        "  # news = 제목 + 날짜 + 본문\n",
        "  news = f\"\"\"<뉴스 제목>: {news_title},\n",
        "  <뉴스 생성일자>: {news_date},\n",
        "  <뉴스 본문>: {news_article}\"\"\"\n",
        "\n",
        "  # news 기반으로 질문 3개 생성\n",
        "  question_list = chain_1.invoke({\"input\": news})\n",
        "\n",
        "  # 질문 3개에 대해 news 기반으로 답변\n",
        "  answer_list_news = chain_2.invoke({\"input\": news, \"question\": question_list})\n",
        "\n",
        "  # 질문 3개에 대해 blog 기반으로 답변\n",
        "  answer_list_blog = chain_3.invoke({\"input\": blog, \"question\": question_list})\n",
        "\n",
        "  # 일치 여부 판단(True/False)\n",
        "  return answer_list_news == answer_list_blog"
      ],
      "metadata": {
        "id": "G_kvYLxpm0RO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **적용 예시**\n",
        "## **데이터 준비**"
      ],
      "metadata": {
        "id": "gxauSQUdnJs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [뉴스]\n",
        "\n",
        "# 제목\n",
        "news_title = '\"전쟁난 줄 알았다\"…출근길 직장인 울린 서울 지하철 상황'\n",
        "# 날짜\n",
        "news_date = '2023-07-14 00:00:00'\n",
        "# 본문\n",
        "news_article = \"\"\"\\수인분당선 왕십리역에서 열차를 기다리는 시민들이 대거 몰려있는 모습. /사진=김세린 기자 14일 서울에 많은 비가 내리면서 일부 도로의 출입이 전면 통제된 가운데, 출근길 지하철로 몰린 시민들이 곳곳에서 불편함을 호소했다. 이날 오전 4시10분께 출입이 통제된 동부간선도로 전 구간(수락지하차도~성수JC)은 오전 6시 40분께 통행이 재개됐으나, 오전 7시 15분께부터는 올림픽대로(양방향) 여의상류IC 교통 통제가 시작됐다. 서울시 재난안전대책본부는 시민들에게 미리 도로 교통 상황을 확인하고, 가급적 대중교통을 이용해 달라고 당부했다. 이에 일부 지하철 노선에 사람이 대거 몰리게 된 것으로 풀이된다. 수서역에서 왕십리역 방향 열차 지연으로 대기 중이던 시민들이 열차 탑승을 기다리고 있다. /사진=김세린 기자 이날 오전 8시께 수인 분당선 수서역에서 왕십리로 향하는 열차는 운행이 10~15분가량 지연돼 다음 역인 대모산입구역에서 기다리던 승객들이 대기해야 했다. 이후 재개된 열차는 5대가량이 연이어 몰려오는 상황이 발생했으며, 도착한 열차 내부엔 사람들이 이미 꽉 들어서 한때 원활한 탑승이 어려웠다. 이 구간 종착역인 왕십리에서도 청량리 방면 열차 탑승을 위해 대기 중인 사람들이 빼곡하게 줄지어 들어서 있었다. 시민들 사이에서는 \"전쟁 난 거 아니냐\", \"움직일 수가 없다\", \"오늘 안에 가는 것 맞냐\"는 등의 목소리가 흘러나왔다. 직장인 송모 씨(42)는 \"비가 많이 와서 도로 상황이 안 좋은 것 같아 지하철을 타러 온 건데 이게 무슨 일인지 당황스럽다\"며 \"회사 가는 건 이미 지각이고, 지옥철이라서 불편할 것 같다\"고 토로했다. 지하철 운행이 폭우로 인해 늦어진 것과 관련, 직장인 온라인 커뮤니티 '블라인드'에서도 \"오늘 2호선 역마다 몇분씩 정차하는 것이냐\", \"출근 시간에 지하철 왜 이러는 거냐\", \"오늘 지하철 왜 이러냐 지각 당첨이다\" 등의 반응이 나왔다. 집중호우가 내린 14일 오전 서울 잠수교가 강물에 잠겨 통제되고 있다. /사진=뉴스1 이외에도 폭우로 인한 피해도 계속된다. 밤사이 세찬 비가 이어지면서 서울 2개 구 4000여세대에서 정전 피해가 발생했으며, 전국 6개 시도 21개 시군구 134명이 일시 대피했다. 한편 기상청에 따르면 오늘까지 서울과 인천, 경기 북부, 강원중·북부 내륙·산지에 돌풍과 천둥·번개를 동반한 시간당 30∼80mm의 매우 강한 비가 내린다. 행정안전부는 위기 경보 수준을 '경계'에서 최고 수준인 '심각' 단계로 상향하고 중앙재난안전대책본부(중대본) 2단계를 3단계로 올리기로 했다.\"\"\" # 본문\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# [블로그]\n",
        "\n",
        "blog_sample = \"\"\"\n",
        "## \"폭우에 막힌 서울의 아침: 지하철 연착으로 출근길 뒤숭숭\"\n",
        "\n",
        "## 시작하는 말:\n",
        "안녕하세요, 여러분의 출퇴근 메신저 지하철 온다의 '오.지.통 [오늘의 지하철 소식통]' 인사 드립니다!\n",
        "\n",
        "-{지연/사고 일시}: 2023년 7월 14일 오전\n",
        "-{지연/사고 노선}: 수인분당선\n",
        "-{지연/사고 이유}: 강한 폭우로 인한 노선 일부 구간의 도로 출입 통제 및 대체 대중교통 수요 급증\n",
        "-{문의 사항}: [서울교통공사 홈페이지](https://www.seoulmetro.co.kr)\n",
        "\n",
        "## 간단한 요약글:\n",
        "지난 14일, 서울을 포함한 수도권에 내린 집중 호우로 인해 많은 도로가 통제되었고, 대중교통 이용에 큰 차질이 빚어졌습니다. 특히 수인분당선에서는 수서역에서 왕십리역 방향으로 향하는 열차가 평소보다 10~15분 가량 지연되었으며, 이로 인해 승객들이 열차 내부에서 긴 대기 시간을 겪어야 했습니다. 또한, 청량리 방향으로 가는 열차를 기다리는 승객들로 인해 왕십리역이 빼곡히 들어차 원활한 탑승이 어려운 상황이었습니다. 이러한 상황은 출근 시간대에 직장인들 사이에서 큰 불편을 초래했습니다.\n",
        "\n",
        "## 마무리 말:\n",
        "오지통이 실시간으로 다양한 지하철 정보를 업데이트 할 예정이니, 자주 방문해 주세요. '지하철 온다'는 단 한 번의 터치로 자신의 위치에서 가장 가까운 지하철역의 실시간 도착 정보를 제공합니다. 아침마다 이런 사태로 지각이 걱정되시죠? 우리 함께 잘 대비해봅시다!\n",
        "\n",
        "🔽 지하철 온다 소개 보러가기\n",
        "\n",
        "https://blog.naver.com/subway__onda/223258646349\"\"\""
      ],
      "metadata": {
        "id": "WOMTceL8nHfI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quan_eval(news_title, news_date, news_article, blog_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLlndUWTnKQo",
        "outputId": "1f4cda83-86c1-449c-e1dd-1e808534e460"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}