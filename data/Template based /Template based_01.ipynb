{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f93cbe1-e867-4e80-bece-7d7402596333",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42578762-b7da-47a0-8a45-f67aff6be7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3578a736-bd8c-43b9-83c7-384b1999d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# 환경변수에 OpenAI API 키 저장 (사용자 입력으로 안전하게)\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baef42af-f92c-46e3-8b91-24ff33b88b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.46 (from langchain_openai)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting openai<2.0.0,>=1.24.0 (from langchain_openai)\n",
      "  Downloading openai-1.29.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
      "  Downloading langsmith-0.1.57-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.10.2)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.0.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.8.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.5.2->langchain_openai)\n",
      "  Downloading regex-2024.5.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.28.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.4)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
      "  Downloading orjson-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (1.26.12)\n",
      "Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
      "Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.29.0-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.3/320.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.57-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.2/785.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading orjson-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, regex, orjson, httpcore, distro, tiktoken, langsmith, httpx, openai, langchain-core, langchain_openai\n",
      "Successfully installed distro-1.9.0 httpcore-1.0.5 httpx-0.27.0 langchain-core-0.1.52 langchain_openai-0.1.6 langsmith-0.1.57 openai-1.29.0 orjson-3.10.3 regex-2024.5.10 tenacity-8.3.0 tiktoken-0.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1fbe2-e49e-4c29-82bb-bbe7d0d2be6d",
   "metadata": {},
   "source": [
    "## 제로샷 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c97ff926-aea9-41ff-958d-58cc20ead1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제로샷\n",
    "zero_template = \"\"\"\n",
    "\n",
    "블로그 글을 작성해줘\n",
    "\n",
    "{input}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787760a-aab0-4cac-bdf9-52a919f56f69",
   "metadata": {},
   "source": [
    "## 지연/사고 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9f08bb-a7fb-40a4-b5b8-783e2d69a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지연사고 템플릿\n",
    "prompt_template = \"\"\"\n",
    "너는 지금부터 블로그 포스팅 전문 콘텐츠 마케터야.\n",
    "너는 항상 최선을 다하고 좋은 글을 작성해서 나를 기쁘게 해주고 있어.\n",
    "아래의 형식으로 작성해줘:\n",
    "\n",
    "{input}\n",
    "\n",
    "1) 제목과 본문으로 구분해서 출력해줘.\n",
    "2) 제목은 창의력 있고, 주목도 있게 구성해줘.\n",
    "3) 본문을 구성할 때는 Google과 Naver 검색의 검색엔진최적화(SEO)에 맞게 포스팅을 해줘\n",
    "4) 최대한 자세하게 작성해주고 신뢰도 있는 정보를 중심으로 포스팅을 해줘\n",
    "5) 글의 길이는 기본적으로 A4용지 1장 길이로 작성해줘\n",
    "6) 간단 요약부분과 마지막말은 대학생 블로그 글 서포터즈가 쓴 글 처럼 통통튀고 발랄한 말투로 작성해줘\n",
    "7) 공감하는 말을 추가해줘 ex) 지하철 파업으로 아침마다 출근하기 힘드네요\n",
    "\n",
    "템플릿:\n",
    "{{여기에 블로그 제목}}\n",
    "{{시작하는 말}}\n",
    "안녕하세요, 여러분의 출퇴근 메신저 지하철 온다의 '오.지.통 [오늘의 지하철 소식통]' 인사 드립니다!\n",
    "\n",
    "{{지연/사고 일시}}\n",
    "{{지연/사고 노선}}\n",
    "{{지연/사고 이유}}\n",
    "{{문의 사항 링크}}\n",
    "\n",
    "{{간단한 요약글}}\n",
    "\n",
    "{{마무리 말}}\n",
    "오지통이 실시간으로 다양한 지하철 정보를업데이트 할 예정이니, 자주 방문해 주세요. \n",
    "'지하철 온다'는 단 한 번의 터치로 자신의 위치에서 가장 가까운 지하철 역의 실시간 정보를 제공합니다.\n",
    "\n",
    "🔽 지하철 온다 소개 보러가기\n",
    "https://blog.naver.com/subway__onda/223258646349\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a710c00-0e13-45cb-b9f2-f7a3dff1c080",
   "metadata": {},
   "source": [
    "## 평가 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba0afa9-4f15-4dbe-bb14-7eb1da0ddd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Consistency_template = \"\"\"\n",
    "\n",
    "Compare and evaluate the blog content you created with the article.\n",
    "First, Extract the key information from the article ( time,date,subway line)\n",
    "You need to decide whether the key information is entailed by the  CONTEXT by choosing one of the following rating: \n",
    "\n",
    "1. 5 point: The blog content follows logically from the information contained in the article. \n",
    "\n",
    "2. 1 point: The blog content is logically false from the information contained in the article. \n",
    "\n",
    "3. an integer score between 1 and 5 and if such integer score does not exist,  \n",
    "\n",
    "use 1: It is not possible to determine whether the blog content is true or false without further information. \n",
    "\n",
    "Read the passage of information thoroughly and select the correct answer from the three answer labels. \n",
    "\n",
    "Read the CONTEXT thoroughly to ensure you know what the CONTEXT entails.  \n",
    "\n",
    "Note the blog content is generated by a computer system, it can contain certain symbols, which should not be a negative factor in the evaluation.\n",
    "\n",
    "\n",
    "blog content\n",
    "{input1}\n",
    "\n",
    "article\n",
    "{input2}\n",
    "\n",
    "Evaluation Form (scores ONLY):\n",
    "\n",
    "{{score}}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f80c8f-49de-4cfc-9f60-937509a36e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coherence_template = \"\"\"\n",
    "\n",
    "Your task is to rate the blog content on one metric.\n",
    "\n",
    "Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "Coherence (1-5) - the collective quality of all sentences. We align this dimension with the DUC quality question of structure and coherence whereby \"the summary should be well-structured and well-organized. The summary should not just be a heap of related information, but should build from sentence to a coherent body of information about a topic.\"\n",
    "\n",
    "Evaluation Steps:\n",
    "\n",
    "1. Read the news article carefully and identify the main topic and key points.\n",
    "2. Read the blog content and compare it to the news article. Check if the summary covers the main topic and key points of the news article, and if it presents them in a clear and logical order.\n",
    "3. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\n",
    "\n",
    "\n",
    "{input}\n",
    "\n",
    "Evaluation Form (scores ONLY):\n",
    "\n",
    "\n",
    "{{score}}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260fb2ae-f589-41b5-a86c-23f90e614c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Friendliness_template = \"\"\"\n",
    "Friendliness, as a metric, measures how effectively the text of a blog content engages the reader with a friendly and inviting tone. If the tone and style of the text foster a sense of warmth and familiarity, making the reader feel welcomed and engaged, then the value of the Friendliness metric should be high; otherwise, it should be low. After reading the blog post, evaluate its tone and style against typical friendly communication, and determine the value of the Friendliness metric using the following rating scale:\n",
    "\n",
    "- One star: The tone is cold or unfriendly, not engaging the reader in any appreciable way.\n",
    "- Two stars: The tone has minimal warmth, slightly engaging but largely formal or distant.\n",
    "- Three stars: The tone is moderately friendly, balancing formal and informal elements to somewhat engage the reader.\n",
    "- Four stars: The tone is very friendly, actively engaging the reader with warmth and lively expressions.\n",
    "- Five stars: The tone is exceptionally friendly and lively, creating a strong sense of connection and engagement with the reader.\n",
    "\n",
    "This rating should always be an integer between 1 and 5. Thus, the rating produced should be 1, 2, 3, 4, or 5, based on your assessment of how friendly and engaging the text is towards the read.\n",
    "\n",
    "\n",
    "{input}\n",
    "\n",
    "Evaluation Template (Score Only):\n",
    "\n",
    "\n",
    "{{score}}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6c3071-f36f-44a2-852c-51fb9f00b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿\n",
    "Fluency_template = \"\"\"\n",
    "Fluency measures the quality of individual sentences in the answer, and whether they are well-written and grammatically correct. Consider the quality of individual sentences when evaluating fluency. Given the question and answer, score the fluency of the answer between one to five stars using the following rating scale: \n",
    "\n",
    "One star: the answer completely lacks fluency \n",
    "\n",
    "Two stars: the answer mostly lacks fluency \n",
    "\n",
    "Three stars: the answer is partially fluent \n",
    "\n",
    "Four stars: the answer is mostly fluent \n",
    "\n",
    "Five stars: the answer has perfect fluency \n",
    "\n",
    "This rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.\n",
    "\n",
    "\n",
    "{input}\n",
    "\n",
    "\n",
    "Evaluation Template (Score Only):\n",
    "\n",
    "\n",
    "{{score}}\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e41bde8-17e7-4085-9a91-9a99566d276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Humanlikeness_template = \"\"\"\n",
    "Humanlikeness, as a metric, evaluates how closely the style and delivery of GPT-generated text resemble that of naturally written human text. If the text is indistinguishable from human writing in terms of natural flow, vocabulary use, and contextual accuracy, then the value of the Human-likeness metric should be high; otherwise, it should be low. Given the text generated by GPT and comparing it to typical human-written text, determine the value of the Human-likeness metric using the following rating scale:\n",
    "\n",
    "- One star: The text is entirely machine-like, with unnatural flow and numerous contextual errors.\n",
    "- Two stars: The text is mostly machine-like, with frequent unnatural expressions and noticeable errors.\n",
    "- Three stars: The text is somewhat human-like, showing signs of natural language use but with some mechanical characteristics.\n",
    "- Four stars: The text is mostly human-like, with very few mechanical traits and generally natural language use.\n",
    "- Five stars: The text is completely human-like, indistinguishable from something a human might write.\n",
    "\n",
    "This rating should always be an integer between 1 and 5. Thus, the rating produced should be 1, 2, 3, 4, or 5, based on the evaluation.\n",
    "\n",
    "\n",
    "{input}\n",
    "\n",
    "Evaluation Template (Score Only):\n",
    "\n",
    "{{score}}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612eec01-b4e7-456f-8c67-57d54a6c2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Readability_template = \"\"\" \n",
    "To assess the readability of an article, please read and evaluate the presented content carefully. The readability assessment focuses on three main factors\n",
    "\n",
    "1. Sentence length: The sentence should not be excessively long.\n",
    "2. Vocabulary difficulty: We prefer to use everyday, easy-to-understand vocabulary.\n",
    "3. Line breaks and paragraph breaks: A clear structure improves readability.\n",
    "\n",
    "Based on each factor, please rate the overall readability on a integer from 1 to 5. The scoring system is as follows:\n",
    "\n",
    "*  1 point: Very long sentences, difficult vocabulary, and no line breaks or paragraph breaks.\n",
    "\n",
    "*  5 point: Sentence length is reasonable, uses everyday words that are easy to understand, and has good line breaks and paragraph breaks.\n",
    "\n",
    "\n",
    "{input}\n",
    "\n",
    "Evaluation Template (Score Only):\n",
    "\n",
    "{{score}}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f4aef-4a75-4780-8f4e-f383c1c7528e",
   "metadata": {},
   "source": [
    "## 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f08463a-8947-419b-bf4a-dc98b04245c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt + model + output parser\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "zeroprompt = ChatPromptTemplate.from_template(zero_template)\n",
    "delayprompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL chaining\n",
    "zerochain = zeroprompt | llm | output_parser\n",
    "delaychain = delayprompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f589d-2654-4417-9074-fc4f2f62a32b",
   "metadata": {},
   "source": [
    "## 기사 텍스트로 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e91fcbaf-d0dc-4294-bc70-07cb5dc6069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "\n",
    "\"월요일부터 지각\" 지하철 1호선 지연 운행에 시민 불편…\"노조 준법투쟁\"\n",
    "출근 시간 승객 큰 불편…지연 운행에 지각 우려\n",
    "부산―수서 SRT 운행축소에 노조 24일부터 태업\n",
    "\n",
    "(서울=뉴스1) 한병찬 기자 | 2023-08-28 08:26 송고 | 2023-08-28 08:35 최종수정\n",
    "\n",
    "전국철도노동조합(철도노조)의 준법투쟁으로 출근길 서울 지하철 1호선 이용객이 불편을 겪고 있다.\n",
    "\n",
    "28일 뉴스1 취재를 종합하면 1호선 지하철은 철도노조의 태업으로 지연 운행하고 있다. 도심 지하철역은 출근시간대 이용객이 몰리며 큰 혼잡을 빚고 있다.\n",
    "\n",
    "종각역으로 출근하는 20대 김모씨는 \"평소보다 느리게 운행해 열차 안이 승객들로 빽빽했다\"며 \"철도노조 태업 때문에 운행이 지연된다는 안내방송을 하면서 급한 고객은 다른 교통수단을 이용하라는데 그러려면 몇 번이나 환승해야 해 불편하다\"고 답답함을 호소했다. \n",
    "\n",
    "온라인에는 \"1호선 연착으로 지각하게 생겼다\"거나 \"연착이 심해 역사 안에 발 디딜 곳이 없다\" \"개강 첫 날 비까지 오는데 불편하다\" \"퇴근길이 걱정된다\"는 반응이 올라왔다. \n",
    "\n",
    "한국철도공사(코레일) 관계자는 \"특별한 사건 사고가 있는 것은 아니기 때문에 철도노조의 준법투쟁으로 지연 운행되는 것 같다\"면서 \"정확한 지연 시간을 살피고 있다\"고 말했다. \n",
    "철도노조는 국토교통부가 사회적 논의나 공론화 없이 내달 1일부터 부산―수서를 운행하는 SRT 고속열차의 운행을 11% 이상(일일 4100여석) 축소한 것에 반발해 지난 24일부터 준법투쟁(태업)을 하고 있다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf9ceea-7b3d-4de3-8920-4ba57672388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "폭염 속 지하철 1호선 지연… 시민들 ‘짜증’\n",
    "\n",
    "기자명 강현수   입력 2023.08.01 19:01  수정 2023.08.02 10:21\n",
    "\n",
    "전국 대부분 지역에 폭염경보가 내려진 1일 지하철 1호선이 연착돼 이용객들이 불편을 호소했다.\n",
    "\n",
    "코레일(한국철도공사)에 따르면 이날 오후 3시께부터 지하철 1호선이 10분가량 지연되고 있다.\n",
    "\n",
    "1호선을 이용하려던 시민들은 SNS(사회관계망서비스)를 통해 \"날씨가 더워서 기다리기 힘든데 지하철은 잔뜩 밀려있다\", \"1호선은 가뜩이나 역도 야외에 있어서 더운데 기다려야 한다\" 등 반응을 보였다.\n",
    "\n",
    "이와 관련 코레일 관계자는 \"KTX(고속철도)가 폭염 영향으로 지연된 것처럼, 그 영향이 1호선에도 똑같이 적용되긴 한다\"며 \"3시 열차가 지연돼 뒷 열차들도 늦어지고 있는 상황\"이라고 설명했다.\n",
    "\n",
    "강현수기자\n",
    "\n",
    "출처 : 중부일보 - 경기·인천의 든든한 친구(https://www.joongboo.com)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45035b1f-9f36-4593-855d-46cee195a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"\"\"\n",
    "출근길 서울 지하철 7호선 열차 출입문 고장…청담역·산곡역서 잠시 운행 중단 [제보]\n",
    "입력 2023.12.29 (10:53)\n",
    "수정 2023.12.29 (11:20)\n",
    "\n",
    "오늘(29일) 아침, 서울 지하철 7호선 열차가 출입문 고장으로 인해 잠시 운행이 중단됐습니다.\n",
    "\n",
    "오늘 오전 7시 50분쯤 서울 지하철 7호선 청담역 승강장에서 온수행 열차의 출입문이 닫히지 않아 운행이 잠시 중단됐습니다.\n",
    "\n",
    "또 오전 7시 57분쯤 7호선 산곡역의 도봉산행 열차에서도 같은 문제가 발생했습니다.\n",
    "\n",
    "열차에 타고 있던 승객들은 고장 난 열차에서 내린 뒤 2~3분 뒤에 도착한 다음 열차에 탑승해 이동했습니다.\n",
    "\n",
    "이 사고로 다친 승객은 없었지만, 출근 시간대에 열차 운행에 차질이 빚어지면서 출근길 시민들이 큰 불편을 겪었습니다.\n",
    "\n",
    "서울교통공사는 \"7호선 열차는 현재는 모두 정상 운행되고 있으며 정확한 고장 원인을 조사할 계획\"이라고 밝혔습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29ae7559-7ec8-4dee-91a1-8c8099a6930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"\"\"\n",
    "'번쩍'하더니 폭발음...어제 퇴근길 난리 난 지하철 1호선 상황 (+영상)\n",
    "2024-01-04 10:06\n",
    "\n",
    "승객 500여 명 하차한 뒤 환승...일대 혼잡 등 불편 겪어\n",
    "퇴근길 서울지하철 1호선에서 전동차 고장으로 한바탕 소동이 일었다.\n",
    "\n",
    "지난 3일 SBS뉴스 등 보도에 따르면 3일 오후 5시 54분께 경인선(서울지하철 1호선) 전동차가 온수역에서 역곡역으로 운행하던 중 고장으로 멈췄다.\n",
    "\n",
    "이 사고로 열차에 타고 있던 승객 500여 명이 10여 분 동안 터널에 정차한 채 대기했고, 다음 역인 역곡역에서 하차한 뒤 환승하는 불편을 겪었다.\n",
    "\n",
    "또 이 열차 고장으로 인해 경인선 하행선(인천 방면) 오류역∼부천역 구간 후속 열차 운행이 10여 분간 지연됐다.\n",
    "\n",
    "사고 당시 상황이 담긴 영상도 공개됐다. 전동차 유리창 밖으로 번쩍하는 섬광과 함께 폭발음이 들리더니 갑작스럽게 불꽃이 튀기기도 했다. 놀란 승객들은 \"어머, 어떡해\", “얼른 다 내려야겠다”며 자리에서 일어나 당황스러움을 내비쳤다.\n",
    "\n",
    "이와 관련해 코레일 관계자는 \"경인선 상행선(용산 방면) 열차 운행은 지연되지 않았다\"라며 정확한 사고 원인을 조사 중이라는 입장을 밝혔다.\n",
    "\n",
    "앞서 지난해 10월엔 서울지하철 6호선 열차가 문을 연 채 운행하는 일이 벌어졌다.\n",
    "\n",
    "사고는 퇴근 시간대 발생했다. 19일 오후 6시 30분쯤 6호선 응암행 열차가 월곡역에서 출입문 안쪽에 콘크리트 조각이 끼면서 문이 닫히지 않은 상태로 달렸다.\n",
    "\n",
    "서울교통공사는 고려대역에서 승객들을 모두 내리게 한 뒤 열차를 차량기지로 보내는 과정에서 이물질을 제거하고 오후 6시 56분쯤 삼각지역에서 다시 승객을 태웠다.\n",
    "\n",
    "그러나 오후 7시 31분 해당 열차는 연신내역에서 다시 문이 닫히지 않은 장애가 빚어져 운행을 전면 중단하고 차량기지로 돌려보내졌다.\n",
    "\n",
    "다행히 이 과정에서 다친 사람은 없었지만, 혼잡을 빚는 등 승객들이 불편을 겪었다\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ebd96a-1bf2-49c5-917b-bb9fdff2a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = \"\"\"\n",
    "안산역 70대男 쓰러진 채 발견→4호선 한때 중단... 간편지연증명서 발급 방법·기준은?\n",
    "\n",
    "기자명 주지영 기자   입력 2023.02.10 09:32\n",
    "\n",
    "[핀포인트뉴스 주지영 기자] 오늘(10일) 안산역 선로에서 발생한 사상사고로 출근 시간대 4호선 열차 운행에 차질이 발생했다.\n",
    "\n",
    "이날 오전 6시 58분쯤 경기 안산시 단원구 원곡동 지하철 4호선 안산역 선로에서 70대 남성 A씨가 쓰러진 채 발견됐다. \n",
    "\n",
    "A씨는 4호선 서울방향 전동차 하부에서 심정지 상태로 발견됐다. A씨는 소방당국에 의해 인근 병원으로 옮겨졌다. \n",
    "\n",
    "이날 현장감식 등 사고 수습을 위해 4호선 양방향 열차 운행이 잠시 중단됐다. 이후 이날 오전 8시 37분께 안산~오이도역 간 상·하선 전구간 열차운행이 재개됐다.\n",
    "\n",
    "그런 가운데  갑작스러운 지하철 지연 운행으로 출근길 시민들이 불편을 겪으면서 지하철 지연 증명서 발급 방법에 관심이 모아진다. \n",
    "\n",
    "지하철 지연 증명서는 지하철 연착으로 회사, 학교에 늦었을 경우 지각 사유를 뒷받침 할 수 있는 증명서다. 지연된 열차 기준 탑승 3일 이내에 발급 받을 수 있다.\n",
    "\n",
    "서울교통공사의 여객운송약관에 따르면 지하철 지연 기준은 5분으로 5분 이상 지연이 발생했을 때 증명서 발급이 가능하다. \n",
    "\n",
    "KTX, 무궁화호 등은 지하철과 지연 기준이 다르다. 해당 열차를 운영하는 곳은 한국철동고사(코레일)로 이곳 약관에서는 20분 이상 지연이 발생해야 '열차 지연'으로 분류한다. \n",
    "\n",
    "다만 지연 사유가 내부 원인이어야 하며 천재지변, 테러 등은 지연 기준이 아니다.\n",
    "\n",
    "열차 지연 시간은 서울교통공사, 코레일 홈페이지의 간편지연증명서 발급 서비스에서 확인할 수 있다. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11df39e-653f-4441-93f0-0463d1a9de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = delaychain.invoke({\"input\": text1})\n",
    "zero_output1 = zerochain.invoke({\"input\": text1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e491c1ae-3706-4872-b578-fa577cf7ed75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### 월요일 아침, 서울 지하철 1호선 지연 운행으로 시민 불편 가중\\n\\n서울 시민들이 월요일 아침부터 큰 불편을 겪고 있습니다. 이번 주는 시작부터 지하철 1호선의 지연 운행으로 인해 많은 시민들이 출근길에 혼란을 경험하고 있습니다. 전국철도노동조합의 준법투쟁이 이러한 지연의 주된 원인으로 보입니다.\\n\\n#### 지연 원인과 시민들의 불편함\\n\\n28일, 서울 지하철 1호선은 전국철도노동조합의 태업으로 인해 정상적인 시간표보다 늦은 운행을 하고 있습니다. 이로 인해 평소보다 많은 시민들이 도심의 지하철역에서 긴 대기 시간을 보내야만 했습니다. 특히 출근 시간대에 승객이 몰리면서 열차 내부와 역사는 승객들로 가득 찼으며, 많은 이들이 큰 불편을 호소하고 있습니다.\\n\\n한 시민은 \"평소보다 느리게 운행하는 바람에 열차 안이 승객들로 빽빽해 매우 답답했다\"며 불편함을 토로했습니다. 또한, 철도노조의 태업으로 인한 지연 사실을 안내받았지만, 다른 교통수단으로 갈아타기 위해서는 여러 번의 환승이 필요해 더욱 불편함을 느꼈다고 전했습니다.\\n\\n#### 온라인 상의 반응\\n\\n이 문제는 온라인에서도 화제가 되고 있습니다. 많은 네티즌들이 지연으로 인해 지각이 예상된다거나, 역사 안에서 발 디딜 틈이 없을 정도로 혼잡하다는 내용의 글들을 올리고 있습니다. 또한, 개강 첫 날 비까지 내리는 상황에서 추가적인 불편을 겪고 있다는 의견도 있습니다.\\n\\n#### 철도노조의 입장과 향후 전망\\n\\n철도노조는 국토교통부의 일방적인 결정에 대한 반발로 지난 24일부터 준법투쟁을 시작했습니다. 특히, 부산-수서 간 SRT 고속열차 운행 축소 결정에 대해 크게 반발하고 있습니다. 이에 따라, 현재 상황이 언제까지 이어질지, 그리고 어떠한 변화가 있을지 시민들과 이용객들의 관심이 집중되고 있습니다.\\n\\n한국철도공사는 현재 정확한 지연 시간을 파악 중에 있으며, 조속히 상황을 개선하겠다는 입장입니다. 하지만, 철도노조와의 협상이 원만히 이루어지지 않는다면, 이러한 불편은 당분간 계속될 것으로 보입니다.\\n\\n서울 시민들에게는 큰 불편을 끼치고 있는 이 문제가 어떻게 해결될지, 많은 이들의 이목이 집중되고 있습니다.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b6160e-e44a-458d-96bc-bdea691c6f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**출근길 지하철 지연 소동! 철도노조 태업으로 서울 1호선 패닉**\n",
      "\n",
      "\n",
      "안녕하세요, 여러분의 출퇴근 메신저 지하철 온다의 '오.지.통 [오늘의 지하철 소식통]' 인사 드립니다!\n",
      "\n",
      "**지연/사고 일시:** 2023년 8월 28일\n",
      "**지연/사고 노선:** 서울 지하철 1호선\n",
      "**지연/사고 이유:** 전국철도노동조합의 준법투쟁 및 태업\n",
      "**문의 사항 링크:** [코레일 고객센터](https://www.letskorail.com/)\n",
      "\n",
      "오늘 아침, 서울 지하철 1호선을 이용하시는 많은 시민들이 예상치 못한 불편을 겪었습니다. 전국철도노동조합의 준법투쟁으로 인해 지하철 운행이 지연되면서, 출근길이 마비되다시피 했어요. 특히, 종각역과 같은 주요 역에서는 승객들이 몰리며 큰 혼란이 발생했습니다.\n",
      "\n",
      "20대 직장인 김모씨는 \"평소보다 느리게 운행해서 열차 안이 무척 붐볐어요. 급한 사람들은 다른 교통수단을 이용하라는 안내방송도 있었지만, 환승을 여러 번 해야 하는 불편함 때문에 힘들었다\"고 전했습니다. 또한, 온라인에서는 지연으로 인한 지각 우려와 역사 내 혼잡을 호소하는 목소리가 높아졌습니다.\n",
      "\n",
      "한국철도공사 관계자는 \"이번 지연은 특별한 사건이나 사고가 아닌 철도노조의 태업으로 인한 것\"이라며 \"현재 정확한 지연 시간을 파악 중\"이라고 말했습니다. 그러나 철도노조 측은 국토교통부의 SRT 운행 축소 결정에 반발해 이 같은 행동에 나섰다고 밝혔습니다.\n",
      "\n",
      "**간단한 요약글**\n",
      "\n",
      "서울 지하철 1호선이 철도노조의 준법투쟁으로 인해 지연 운행되고 있습니다. 출근길 대혼란으로 이어지는 가운데, 많은 승객들이 불편을 겪고 있습니다. 문제 해결을 위한 논의가 시급해 보입니다.\n",
      "\n",
      "**마무리 말**\n",
      "\n",
      "오지통이 실시간으로 다양한 지하철 정보를업데이트 할 예정이니, 자주 방문해 주세요. '지하철 온다'는 단 한 번의 터치로 자신의 위치에서 가장 가까운 지하철 역의 실시간 정보를 제공합니다.\n",
      "\n",
      "🔽 지하철 온다 소개 보러가기\n",
      "https://blog.naver.com/subway__onda/223258646349\n",
      "\n",
      "지하철 파업으로 아침마다 출근하기 힘드네요, 여러분도 그렇죠? 함께 공감하며, 더 나은 출퇴근 환경을 기대해 봅시다!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "output_final1 = re.sub(r'(\\*\\*[^*]+\\*\\*)\\n', r'\\1\\n\\n', output1)\n",
    "\n",
    "print(output_final1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e82f8e-9952-43b4-ab2c-3ed6d16d01bd",
   "metadata": {},
   "source": [
    "### 템플릿 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec0794d2-4531-4c00-a72a-807287ec35ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Friendliness</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Humanlikeness</th>\n",
       "      <th>Readablitlity</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Consistency  Coherence  Friendliness  Fluency  Humanlikeness  \\\n",
       "0            5          4             3        5              4   \n",
       "\n",
       "   Readablitlity  mean  \n",
       "0              3   4.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 숫자 추출 함수\n",
    "def extract_numbers(text):\n",
    "    # 정규 표현식을 사용하여 문자열에서 숫자 추출\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    return int(numbers[0]) if numbers else None\n",
    "    \n",
    "eval1 = llm.invoke(Consistency_template.format(input1=output_final1,input2=text1))\n",
    "eval2 = llm.invoke(Coherence_template.format(input=output_final1))\n",
    "eval3 = llm.invoke(Friendliness_template.format(input=output_final1))\n",
    "eval4 = llm.invoke(Fluency_template.format(input=output_final1))\n",
    "eval5 = llm.invoke(Humanlikeness_template.format(input=output_final1))\n",
    "eval6 = llm.invoke(Readability_template.format(input=output_final1))\n",
    "\n",
    "eval1 = eval1.content\n",
    "eval2 = eval2.content\n",
    "eval3 = eval3.content\n",
    "eval4 = eval4.content\n",
    "eval5 = eval5.content\n",
    "eval6 = eval6.content\n",
    "\n",
    "\n",
    "eval1_score = extract_numbers(eval1)\n",
    "eval2_score = extract_numbers(eval2)\n",
    "eval3_score = extract_numbers(eval3)\n",
    "eval4_score = extract_numbers(eval4)\n",
    "eval5_score = extract_numbers(eval5)\n",
    "eval6_score = extract_numbers(eval6)\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Consistency': [eval1_score],\n",
    "    'Coherence': [eval2_score],\n",
    "    'Friendliness': [eval3_score],\n",
    "    'Fluency': [eval4_score],\n",
    "    'Humanlikeness': [eval5_score],\n",
    "    'Readablitlity':[eval6_score]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['mean'] = df.mean(axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d956d4-de3d-47ec-8433-c8ce113c18b4",
   "metadata": {},
   "source": [
    "## 제로샷 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7186623-5fd7-44dd-883f-5abd4c025ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Friendliness</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Humanlikeness</th>\n",
       "      <th>Readablitlity</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Consistency  Coherence  Friendliness  Fluency  Humanlikeness  \\\n",
       "0            5          4             2        5              4   \n",
       "\n",
       "   Readablitlity  mean  \n",
       "0              4   4.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval1 = llm.invoke(Consistency_template.format(input1=zero_output1,input2=text1))\n",
    "eval2 = llm.invoke(Coherence_template.format(input=zero_output1))\n",
    "eval3 = llm.invoke(Friendliness_template.format(input=zero_output1))\n",
    "eval4 = llm.invoke(Fluency_template.format(input=zero_output1))\n",
    "eval5 = llm.invoke(Humanlikeness_template.format(input=zero_output1))\n",
    "eval6 = llm.invoke(Readability_template.format(input=zero_output1))\n",
    "\n",
    "eval1 = eval1.content\n",
    "eval2 = eval2.content\n",
    "eval3 = eval3.content\n",
    "eval4 = eval4.content\n",
    "eval5 = eval5.content\n",
    "eval6 = eval6.content\n",
    "\n",
    "\n",
    "eval1_score = extract_numbers(eval1)\n",
    "eval2_score = extract_numbers(eval2)\n",
    "eval3_score = extract_numbers(eval3)\n",
    "eval4_score = extract_numbers(eval4)\n",
    "eval5_score = extract_numbers(eval5)\n",
    "eval6_score = extract_numbers(eval6)\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Consistency': [eval1_score],\n",
    "    'Coherence': [eval2_score],\n",
    "    'Friendliness': [eval3_score],\n",
    "    'Fluency': [eval4_score],\n",
    "    'Humanlikeness': [eval5_score],\n",
    "    'Readablitlity':[eval6_score]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['mean'] = df.mean(axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e6e6e-bd50-408e-a4de-80ab54e46dd1",
   "metadata": {},
   "source": [
    "## 지연/사고 기사 5개 결과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d32e7b3-dbb3-4886-857c-670a8fc4b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = delaychain.invoke({\"input\": text1})\n",
    "output2 = delaychain.invoke({\"input\": text2})\n",
    "output3 = delaychain.invoke({\"input\": text3})\n",
    "output4 = delaychain.invoke({\"input\": text4})\n",
    "output5 = delaychain.invoke({\"input\": text5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc250e85-4d3c-4b1a-8df8-bc4e5bbb2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input in inputs:\n",
    "    final = re.sub(r'(\\*\\*[^*]+\\*\\*)\\n', r'\\1\\n\\n', input)\n",
    "    print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dde36567-674c-40ed-a730-f26107fc5584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Friendliness</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Humanlikeness</th>\n",
       "      <th>Readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\"월요일부터 지각\" 지하철 1호선 지연 운행에 시민 불편…\"노조 준법투쟁\"\\...</td>\n",
       "      <td>**출근길 지각 불가피: 지하철 1호선 연착 사태로 시민 분통!**\\n안녕하세요, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Coherence: 4\\n\\nThe blog content maintains a g...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n폭염 속 지하철 1호선 지연… 시민들 ‘짜증’\\n\\n기자명 강현수   입력 20...</td>\n",
       "      <td>**여름 폭염에 지친 당신, 지하철 1호선도 지쳤다?! 시민들의 무더위 속 대기 시...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>**Evaluation Template (Score Only):**\\n\\n4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n출근길 서울 지하철 7호선 열차 출입문 고장…청담역·산곡역서 잠시 운행 중단 [...</td>\n",
       "      <td>**서울 7호선 아침 출근길 대란! 열차 문 고장으로 운행 중단 사태 발생**\\n\\...</td>\n",
       "      <td>5</td>\n",
       "      <td>Coherence: 4\\n\\nThe blog content effectively s...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Score: 4\\n\\nThe article effectively communicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n'번쩍'하더니 폭발음...어제 퇴근길 난리 난 지하철 1호선 상황 (+영상)\\n...</td>\n",
       "      <td>**제목: 대혼란의 서울지하철 1호선, 퇴근길 갑작스러운 전동차 고장 이슈! (+실...</td>\n",
       "      <td>5</td>\n",
       "      <td>Coherence Score: 4\\n\\nThe blog content provide...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>**Evaluation of Article Readability**\\n\\n1. **...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n안산역 70대男 쓰러진 채 발견→4호선 한때 중단... 간편지연증명서 발급 방법...</td>\n",
       "      <td>### 제목: \"출근길 대혼란! 안산역 사상사고로 인한 4호선 운행 중단, 지연 증...</td>\n",
       "      <td>5</td>\n",
       "      <td>Coherence: 4\\n\\nThe blog content provides a co...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>### Evaluation Template (Score Only):\\n\\n4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\n\\n\"월요일부터 지각\" 지하철 1호선 지연 운행에 시민 불편…\"노조 준법투쟁\"\\...   \n",
       "1  \\n폭염 속 지하철 1호선 지연… 시민들 ‘짜증’\\n\\n기자명 강현수   입력 20...   \n",
       "2  \\n출근길 서울 지하철 7호선 열차 출입문 고장…청담역·산곡역서 잠시 운행 중단 [...   \n",
       "3  \\n'번쩍'하더니 폭발음...어제 퇴근길 난리 난 지하철 1호선 상황 (+영상)\\n...   \n",
       "4  \\n안산역 70대男 쓰러진 채 발견→4호선 한때 중단... 간편지연증명서 발급 방법...   \n",
       "\n",
       "                                              output Consistency  \\\n",
       "0  **출근길 지각 불가피: 지하철 1호선 연착 사태로 시민 분통!**\\n안녕하세요, ...           5   \n",
       "1  **여름 폭염에 지친 당신, 지하철 1호선도 지쳤다?! 시민들의 무더위 속 대기 시...           5   \n",
       "2  **서울 7호선 아침 출근길 대란! 열차 문 고장으로 운행 중단 사태 발생**\\n\\...           5   \n",
       "3  **제목: 대혼란의 서울지하철 1호선, 퇴근길 갑작스러운 전동차 고장 이슈! (+실...           5   \n",
       "4  ### 제목: \"출근길 대혼란! 안산역 사상사고로 인한 4호선 운행 중단, 지연 증...           5   \n",
       "\n",
       "                                           Coherence Friendliness Fluency  \\\n",
       "0  Coherence: 4\\n\\nThe blog content maintains a g...            3       5   \n",
       "1                                                  4            4       5   \n",
       "2  Coherence: 4\\n\\nThe blog content effectively s...            4       5   \n",
       "3  Coherence Score: 4\\n\\nThe blog content provide...            3       5   \n",
       "4  Coherence: 4\\n\\nThe blog content provides a co...            3       5   \n",
       "\n",
       "  Humanlikeness                                        Readability  \n",
       "0             4                                                  3  \n",
       "1             4         **Evaluation Template (Score Only):**\\n\\n4  \n",
       "2             4  Score: 4\\n\\nThe article effectively communicat...  \n",
       "3             4  **Evaluation of Article Readability**\\n\\n1. **...  \n",
       "4             4         ### Evaluation Template (Score Only):\\n\\n4  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력값 리스트\n",
    "inputs = [\n",
    "    (output1, text1),\n",
    "    (output2, text2),\n",
    "    (output3, text3),\n",
    "    (output4, text4),\n",
    "    (output5, text5)\n",
    "]\n",
    "\n",
    "# 평가 항목 / 템플릿\n",
    "evaluations = {\n",
    "    'Consistency': Consistency_template,\n",
    "    'Coherence': Coherence_template,\n",
    "    'Friendliness': Friendliness_template,\n",
    "    'Fluency': Fluency_template,\n",
    "    'Humanlikeness': Humanlikeness_template,\n",
    "    'Readability': Readability_template\n",
    "}\n",
    "\n",
    "# 결과 저장\n",
    "results = []\n",
    "\n",
    "for input1, input2 in inputs:\n",
    "    scores = {}\n",
    "    for eval_name, template in evaluations.items():\n",
    "        if eval_name == 'Consistency':\n",
    "            # Consistency의 경우에는 원본글과 블로그 글 두 입력값이 필요\n",
    "            response = llm.invoke(template.format(input1=input1, input2=input2))\n",
    "        else:\n",
    "            response = llm.invoke(template.format(input=input1))\n",
    "            \n",
    "        scores['text'] = input2\n",
    "        scores['output'] = input1\n",
    "        score = response.content\n",
    "        scores[eval_name] = score\n",
    "    \n",
    "    # 현재 입력에 대한 점수를 결과 리스트에 추가\n",
    "    results.append(scores)\n",
    "\n",
    "# 결과 리스트로 DataFrame 생성\n",
    "df = pd.DataFrame(results)\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3d784f3-0a33-48f4-a10f-e3b3548cb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./delayresult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d8d53-3157-41d6-b965-5b12140fe66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f53306f-c3bb-4bfc-877c-df0f5b27b740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
