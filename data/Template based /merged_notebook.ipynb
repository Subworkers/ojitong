{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee1352d-dd34-4ee2-9c2a-181dbeb28d29",
   "metadata": {},
   "source": [
    "## 1. 필요 라이브러리 설치\n",
    "- Newspaper3k와 Selenium을 사용하여 웹 스크래핑을 수행합니다.\n",
    "- Chromium-browser와 ChromeDriver는 Selenium이 웹 컨텐츠를 효과적으로 스크랩할 수 있도록 합니다.\n",
    "- OpenAI API와 Langchain을 사용하여 텍스트 생성을 수행합니다.\n",
    "- Rouge-score는 생성된 텍스트의 품질을 평가하는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31b611d-1547-4c24-ab29-47b988d6784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n",
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (24.0)\n",
      "Requirement already satisfied: newspaper3k in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.2.8)\n",
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.21.0)\n",
      "Requirement already satisfied: chromedriver-autoinstaller in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.6.4)\n",
      "Requirement already satisfied: webdriver-manager in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.0.1)\n",
      "Requirement already satisfied: lxml_html_clean in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.31.2)\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.1.16)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain_openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.1.4)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: rouge-score in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (4.12.2)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (9.5.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (6.0.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (5.2.2)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (2.31.0)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (6.0.11)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (5.1.2)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.2)\n",
      "Requirement already satisfied: trio~=0.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from chromedriver-autoinstaller) (23.2)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_core-0.2.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (0.1.51)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rouge-score) (2.0.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
      "Requirement already satisfied: sgmllib3k in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.74-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>=3.2.1->newspaper3k) (2023.5.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.10.0->newspaper3k) (3.1.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
      "Downloading langchain-0.2.2-py3-none-any.whl (973 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
      "Downloading langchain_core-0.2.4-py3-none-any.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.74-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m907.0/907.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langsmith, langchain-core, langchain-text-splitters, langchain_openai, langchain\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.6.0\n",
      "    Uninstalling tiktoken-0.6.0:\n",
      "      Successfully uninstalled tiktoken-0.6.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.51\n",
      "    Uninstalling langsmith-0.1.51:\n",
      "      Successfully uninstalled langsmith-0.1.51\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.46\n",
      "    Uninstalling langchain-core-0.1.46:\n",
      "      Successfully uninstalled langchain-core-0.1.46\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.1\n",
      "    Uninstalling langchain-text-splitters-0.0.1:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.1\n",
      "  Attempting uninstall: langchain_openai\n",
      "    Found existing installation: langchain-openai 0.1.4\n",
      "    Uninstalling langchain-openai-0.1.4:\n",
      "      Successfully uninstalled langchain-openai-0.1.4\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.16\n",
      "    Uninstalling langchain-0.1.16:\n",
      "      Successfully uninstalled langchain-0.1.16\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.0.34 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.2.2 langchain-core-0.2.4 langchain-text-splitters-0.2.1 langchain_openai-0.1.8 langsmith-0.1.74 tiktoken-0.7.0\n",
      "Collecting ko-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ko_core_news_lg-3.7.0/ko_core_news_lg-3.7.0-py3-none-any.whl (230.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ko-core-news-lg==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (8.1.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.1.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ko_core_news_lg')\n",
      "Installation complete.\n"
     ]
    }
   ],
   "source": [
    "# Upgrade pip and install necessary Python libraries\n",
    "!pip3 install --upgrade pip\n",
    "!pip3 install --upgrade newspaper3k selenium chromedriver-autoinstaller webdriver-manager lxml_html_clean openai langchain langchain_openai rouge-score\n",
    "\n",
    "# Download spaCy Korean model\n",
    "!python3 -m spacy download ko_core_news_lg\n",
    "\n",
    "!echo \"Installation complete.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f91fc5-0f9e-4aae-95b3-d1c6419adf18",
   "metadata": {
    "id": "81f91fc5-0f9e-4aae-95b3-d1c6419adf18"
   },
   "source": [
    "# 2. 라이브러리 불러오기\n",
    "웹 스크래핑 및 텍스트 생성에 필요한 라이브러리를 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4421f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a2c736-56c3-429d-a2b7-c86706927076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from rouge_score import rouge_scorer\n",
    "import re\n",
    "import requests\n",
    "import openai\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c454a8e-d463-4670-bc75-64103473cc21",
   "metadata": {},
   "source": [
    "# 3 데이터 수집 및 전처리 - knowledge generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b4cc0-f2b1-44cf-8047-bef5e5dcc335",
   "metadata": {},
   "source": [
    "## 1) 뉴스 URL 가져오기\n",
    "- 네이버 뉴스에서 주어진 검색어로 뉴스 기사의 URL을 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dac4cc95-277c-4308-a0a8-b70d1b8512f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_urls(query):\n",
    "    # 오늘 날짜 형식 생성\n",
    "    #today = datetime.now().strftime('%Y.%m.%d.')\n",
    "    #today_filter = datetime.now().strftime('%Y%m%d')\n",
    "    today='24.06.06'\n",
    "    today_filter='240606'\n",
    "\n",
    "    # '1일' 필터를 적용한 검색 URL\n",
    "    search_url = f\"https://search.naver.com/search.naver?where=news&query={query}&sort=1&ds={today}&de={today}&nso=so%3Ar%2Cp%3Afrom{today_filter}to{today_filter}\"\n",
    "\n",
    "    response = requests.get(search_url, headers={'User-agent': 'Mozilla/5.0'})\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        news_urls = []\n",
    "        for news_area in soup.find_all('div', class_='news_area'):\n",
    "            # 기사 URL 추출\n",
    "            title_element = news_area.find('a', class_='news_tit')\n",
    "            # 날짜 정보 추출\n",
    "            date_element = news_area.find('span', class_='info')\n",
    "            \n",
    "            if title_element and date_element and (today in date_element.text or '시간 전' in date_element.text or '분 전' in date_element.text):\n",
    "                news_urls.append(title_element['href'])\n",
    "        \n",
    "        return news_urls\n",
    "    else:\n",
    "        print(\"Failed to fetch news URLs\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1e9ec-d9b1-4dfc-ba3b-4aead4cc4608",
   "metadata": {},
   "source": [
    "## 2)뉴스 기사 스크래핑\n",
    "- 추출한 URL에서 뉴스 기사의 세부 정보를 스크래핑합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57f9979a-1aaa-4d8d-8a45-d22512491165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_news_articles(news_urls):\n",
    "    articles_data = []\n",
    "    for url in news_urls:\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            articles_data.append({\n",
    "                'url': url,\n",
    "                'title': article.title,\n",
    "                'authors': article.authors,\n",
    "                'publish_date': article.publish_date,\n",
    "                'text': article.text\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape article from {url}: {e}\")\n",
    "    return articles_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352a192-f773-449f-aeb0-1534db41beaf",
   "metadata": {},
   "source": [
    "## 3)  메인 스크립트\n",
    "- 뉴스 기사를 검색하고 스크래핑하여 데이터프레임으로 저장합니다. Selenium을 사용하여 추가 데이터를 수집합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c6226f6-e6ba-4924-9c5c-baf76b0d98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    queries = [\"서울 지하철 파업\", \"서울 지하철 연착\", \"서울 지하철 지연\", \"서울 지하철 사고\", \"서울 지하철 연장\"]\n",
    "    all_articles_data = []\n",
    "    for query in queries:\n",
    "        news_urls = get_news_urls(query)\n",
    "        articles_data = scrape_news_articles(news_urls)\n",
    "        for article_data in articles_data:\n",
    "            article_data['category'] = query.split(\" \")[-1]\n",
    "        all_articles_data.extend(articles_data)\n",
    "    df = pd.DataFrame(all_articles_data)\n",
    "    df = df.replace('', np.nan)\n",
    "\n",
    "    # Selenium 설정 및 데이터 추가 수집\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--remote-debugging-port=9222')  # This can help avoid some common errors\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row['text']) or len(row['text']) < 200:\n",
    "            try:\n",
    "                driver.get(row['url'])\n",
    "                try:\n",
    "                    fetched_text = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.ID, 'pnlContent'))\n",
    "                    ).text\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    try:\n",
    "                        fetched_text = WebDriverWait(driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.TAG_NAME, 'article'))\n",
    "                        ).text\n",
    "                    except (NoSuchElementException, TimeoutException):\n",
    "                        try:\n",
    "                            fetched_text = WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_element_located((By.CLASS_NAME, 'view_cont'))\n",
    "                            ).text\n",
    "                        except (NoSuchElementException, TimeoutException):\n",
    "                            try:\n",
    "                                fetched_text = WebDriverWait(driver, 10).until(\n",
    "                                    EC.presence_of_element_located((By.CLASS_NAME, 'article_body'))\n",
    "                                ).text\n",
    "                            except (NoSuchElementException, TimeoutException):\n",
    "                                try:\n",
    "                                    fetched_text = WebDriverWait(driver, 10).until(\n",
    "                                        EC.presence_of_element_located((By.CLASS_NAME, 'article-body'))\n",
    "                                    ).text\n",
    "                                except (NoSuchElementException, TimeoutException):\n",
    "                                    fetched_text = \"\"\n",
    "                df.at[index, 'text'] = fetched_text\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching article from {row['url']}: {e}\")\n",
    "    \n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141be8e1-56fb-44b6-bda9-0b3976b5c947",
   "metadata": {},
   "source": [
    "## 4) KBS 뉴스 제목 수정\n",
    "Selenium을 사용하여 KBS 뉴스의 제목을 실제 제목으로 업데이트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "320a8b7d-033f-458e-8441-c0b446815e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 창 없는 모드\n",
    "chrome_options.add_argument('--no-sandbox')  # 샌드박스 사용 안 함\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')  # /dev/shm 사용 안 함\n",
    "chrome_options.add_argument('--disable-gpu')  # GPU 가속 사용 안 함\n",
    "chrome_options.add_argument('blink-settings=imagesEnabled=false')  # 이미지 로드 안 함\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "driver.set_page_load_timeout(30)  # 페이지 로딩 타임아웃 30초 설정\n",
    "\n",
    "try:\n",
    "    for index,row in df.iterrows():\n",
    "        if row['title'] == 'KBS 뉴스':\n",
    "            driver.get(row['url'])\n",
    "            try:\n",
    "                # 요소가 화면에 보일 때까지 기다린 후 해당 요소를 찾아 텍스트를 추출\n",
    "                element = WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_element_located((By.CSS_SELECTOR, \"h4.headline-title\"))\n",
    "                    )\n",
    "                real_title = element.text\n",
    "                df.at[index, 'title'] = real_title  # 실제 제목으로 업데이트\n",
    "            except (NoSuchElementException, TimeoutException, WebDriverException) as e:\n",
    "                print(f\"An error occurred for URL {row['url']}: {e}\")\n",
    "finally:\n",
    "    driver.quit()  # 드라이버 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21490629-3ea3-4d12-b738-fab7d64a0135",
   "metadata": {},
   "source": [
    "# 3. 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f52b11c-ab75-42ae-acf4-b38dbdcf9d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "79e1bd8c-ee47-4bb4-a935-2507377757fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype                                \n",
      "---  ------        --------------  -----                                \n",
      " 0   url           2 non-null      object                               \n",
      " 1   title         2 non-null      object                               \n",
      " 2   authors       2 non-null      object                               \n",
      " 3   publish_date  1 non-null      datetime64[ns, tzoffset(None, 32400)]\n",
      " 4   text          2 non-null      object                               \n",
      " 5   category      2 non-null      object                               \n",
      "dtypes: datetime64[ns, tzoffset(None, 32400)](1), object(5)\n",
      "memory usage: 228.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a6fa549-10f8-4a6b-a699-ee32689ebfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.jnilbo.com/73831154967</td>\n",
       "      <td>출근길 지하철</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>출근길 지하철. 2021년 12월 바쁜 출근길 아침, 서울 시내 지하철역에 한 무리...</td>\n",
       "      <td>지연</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.hansbiz.co.kr/news/articleView.html...</td>\n",
       "      <td>[이슈포커스] 물가 둔화 맞아?..장바구니 물가 언제쯤 안정되나</td>\n",
       "      <td>[]</td>\n",
       "      <td>2024-06-06 06:00:00+09:00</td>\n",
       "      <td>내용요약 소비자물가 상승률 두달 연속 둔화\\n\\n반면 '밥상물가'는 여전히 고공행진...</td>\n",
       "      <td>연장</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   \n",
       "0                  http://www.jnilbo.com/73831154967  \\\n",
       "1  http://www.hansbiz.co.kr/news/articleView.html...   \n",
       "\n",
       "                                 title authors              publish_date   \n",
       "0                              출근길 지하철      []                       NaT  \\\n",
       "1  [이슈포커스] 물가 둔화 맞아?..장바구니 물가 언제쯤 안정되나      [] 2024-06-06 06:00:00+09:00   \n",
       "\n",
       "                                                text category  \n",
       "0  출근길 지하철. 2021년 12월 바쁜 출근길 아침, 서울 시내 지하철역에 한 무리...       지연  \n",
       "1  내용요약 소비자물가 상승률 두달 연속 둔화\\n\\n반면 '밥상물가'는 여전히 고공행진...       연장  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eea470-591e-47e9-9026-c460bbefd5df",
   "metadata": {},
   "source": [
    "# 4. 데이터 선택 - knowledge selection\n",
    "- publish_date의 null 값 처리를 위해 한번더 selenium 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d2e7d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941b87e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "628debe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ko-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ko_core_news_lg-3.7.0/ko_core_news_lg-3.7.0-py3-none-any.whl (230.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ko-core-news-lg==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (8.1.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.1.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ko-core-news-lg==3.7.0) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ko_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download ko_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57426df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5cbd598-f7ec-4b5e-b4e3-093ed48d8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the Korean model from spaCy\n",
    "nlp = spacy.load('ko_core_news_lg')\n",
    "\n",
    "# Load KoBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "model = BertModel.from_pretrained('monologg/kobert')\n",
    "\n",
    "# Define related and action words\n",
    "related_words = [\n",
    "    \"지하철\", \"교통\", \"운행\", \"노선\", \"승객\", \"출근\", \"전철\", \"메트로\", \"지하철역\", \"승강장\", \"지하철차량\",\n",
    "    \"대중교통\", \"교통체계\", \"교통망\", \"환승\", \"전용차선\"\n",
    "]\n",
    "\n",
    "action_words = [\n",
    "    \"파업\", \"지연\", \"연착\", \"중단\", \"정지\", \"혼잡\", \"운행지연\", \"운행중단\", \"서비스중단\", \"파업예고\",\n",
    "    \"노동쟁의\", \"노조활동\", \"노사협상\", \"안전점검\", \"사고\", \"충돌\", \"부상\", \"사망\", \"운행변경\",\n",
    "    \"노선변경\", \"시간표변경\", \"대체교통\", \"운행재개\", \"시위\"\n",
    "]\n",
    "\n",
    "# Function to check dependency and entities\n",
    "def check_dependency_and_entities(text):\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.lemma_ in action_words:\n",
    "            neighborhood = list(token.children) + list(token.ancestors) + list(token.subtree)\n",
    "            for neighbor in neighborhood:\n",
    "                if neighbor.lemma_ in related_words:\n",
    "                    if any(child.dep_ == \"neg\" for child in neighbor.children):\n",
    "                        continue\n",
    "                    return True\n",
    "                if neighbor.pos_ in [\"ADP\", \"SCONJ\"]:\n",
    "                    connected_words = [child.lemma_ for child in neighbor.children]\n",
    "                    if set(connected_words).intersection(related_words):\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# Function to check topic relevance using BERT embeddings\n",
    "def check_topics(text, reference_texts):\n",
    "    text_embedding = get_bert_embedding(text)\n",
    "    reference_embeddings = [get_bert_embedding(ref) for ref in reference_texts]\n",
    "    similarities = [cosine_similarity(text_embedding, ref_emb)[0][0] for ref_emb in reference_embeddings]\n",
    "    return max(similarities) > 0.8  # Adjusted threshold for relevance\n",
    "\n",
    "# Load your dataframe (assuming df is already defined and has a 'text' column)\n",
    "reference_texts = [\n",
    "    \"지하철 파업으로 인한 운행 중단\",\n",
    "    \"지하철 사고 발생\",\n",
    "    \"지하철 연착 문제\",\n",
    "    \"지하철 노선 변경\",\n",
    "    \"지하철 운행 재개\",\n",
    "    \"지하철 서비스 중단\",\n",
    "    \"지하철 안전 점검\",\n",
    "    \"지하철 충돌 사고\",\n",
    "    \"지하철 승객 혼잡\",\n",
    "    \"지하철 출근 시간 문제\",\n",
    "    \"지하철 노조 파업\",\n",
    "    \"지하철 운행 변경\",\n",
    "    \"지하철 대체 교통\"\n",
    "]\n",
    "\n",
    "# Check if the document is relevant\n",
    "def is_relevant_document(title):\n",
    "    return check_dependency_and_entities(title) or check_topics(title, reference_texts)\n",
    "\n",
    "# Assuming df is already defined and has a 'title' column\n",
    "df['is_relevant'] = df['title'].apply(is_relevant_document)\n",
    "df = df[df['is_relevant']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3578a736-bd8c-43b9-83c7-384b1999d0d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3578a736-bd8c-43b9-83c7-384b1999d0d1",
    "outputId": "f5e6af6d-270e-484a-d6f6-87065729f2cc"
   },
   "outputs": [],
   "source": [
    "# API 키가 저장된 파일 경로\n",
    "api_key_file = 'api_key.txt'\n",
    "\n",
    "# 파일에서 API 키를 읽어 환경 변수에 저장\n",
    "with open(api_key_file, 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# OpenAI API를 사용할 준비\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ee42ad9-45a9-4d30-b045-1f5e777aa078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['indexed_title'] = df.index.astype(str) + \": \" + df['title']\n",
    "titles = \"\\n\".join(df['indexed_title'].tolist())\n",
    "prompt = f\"\"\"\n",
    "해당 기사 중에서 핵심 주제가 지하철 파업, 지연, 연착, 사고, 노선 연장인 기사들만 뽑아서 행 인덱스 번호만 나열해줘:\n",
    "{titles}\n",
    "\"\"\"\n",
    "newsprompt = ChatPromptTemplate.from_template(prompt)\n",
    "output_parser = StrOutputParser()\n",
    "newschain = newsprompt | llm | output_parser\n",
    "news_output1 = newschain.invoke({\"titles\": titles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a62b3b6d-52d3-4f32-81b0-1043f21b4be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_output1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490e51f-e34d-49b7-8e23-cb8afe16033e",
   "metadata": {},
   "source": [
    "# 5. 데이터 추출 - knowledge injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2b2f0-1c64-4862-96b4-4f30b4f1af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열을 리스트로 변환\n",
    "indices = [int(x.strip()) for x in news_output1.split(',')]\n",
    "\n",
    "# 유효한 인덱스만 필터링\n",
    "valid_indices = [i for i in indices if i < len(df)]\n",
    "\n",
    "# 데이터프레임에서 해당 행만 추출\n",
    "df = df.iloc[valid_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71124c-32a2-4a3c-ac00-e9fd121148a9",
   "metadata": {},
   "source": [
    "# 6. 텍스트 주입 - text injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787760a-aab0-4cac-bdf9-52a919f56f69",
   "metadata": {
    "id": "f787760a-aab0-4cac-bdf9-52a919f56f69"
   },
   "source": [
    "### 1) 지연/파업 템플릿 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c84901-b6e2-4fbb-a1aa-3e8b12b61d16",
   "metadata": {
    "id": "45c84901-b6e2-4fbb-a1aa-3e8b12b61d16"
   },
   "outputs": [],
   "source": [
    "template=pd.read_csv(\"template.csv\")\n",
    "delay_template=template.iloc[0,2]\n",
    "strike_template=template.iloc[1,2]\n",
    "timetable_template=template.iloc[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff30f93-e8c5-4f88-b40c-51512244fb5f",
   "metadata": {
    "id": "1ff30f93-e8c5-4f88-b40c-51512244fb5f"
   },
   "source": [
    "### 2) Text_generation 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a17c77-c5a6-481d-8592-67851ded3a63",
   "metadata": {
    "id": "51a17c77-c5a6-481d-8592-67851ded3a63"
   },
   "outputs": [],
   "source": [
    "def text_generation(source_content,category):\n",
    "    #지연\n",
    "    if category==\"지연\" or category ==\"연착\":\n",
    "        prompt_template=delay_template\n",
    "        chain_lst=[\"지연/사고 일시\",\"지연/사고 노선\",\"지연/사고 이유\"]\n",
    "    #파업\n",
    "    elif category==\"파업\":\n",
    "        prompt_template=strike_template\n",
    "        chain_lst=[\"파업 일시\",\"파업 노선\",\"파업 이유\"]\n",
    "\n",
    "    # 시간표변경\n",
    "    elif category == \"시간표 변경\":\n",
    "        prompt_template = timetable_template  \n",
    "        \n",
    "        # prompt_template을 바로 사용하여 결과 생성\n",
    "        timeprompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        timechain = LLMChain(llm=llm, prompt=timeprompt)\n",
    "        response = timechain(source_content)\n",
    "        return response[\"blogtext\"]    \n",
    "\n",
    "    \n",
    "    prompt = ChatPromptTemplate(\n",
    "    template=prompt_template,\n",
    "    messages=[\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"Objective:\n",
    "    Learn subway information through chaining and use that information to write a coherent and informative blog post using a template.\n",
    "    Basic Setting\n",
    "    Your name is Jitong.\n",
    "    You are a subway information supporter and a Naver Blog Power Blogger.\n",
    "    You are well-informed about information and value communication with readers.\n",
    "    Your goal is to help subway users by providing accurate and practical information for convenient and safe subway use.\n",
    "    \n",
    "    Features and Activities\n",
    "    You read the latest news related to subway \"\"\"+ category+\"\"\", and write blog posts to accurately deliver these in a readable and high-quality manner to readers.\n",
    "    You alleviate readers' inconveniences and speak empathetically through the blog, understanding the sentiments of subway users.\n",
    "    \n",
    "    Communication Style\n",
    "    You use professional yet warm and easy-to-understand language.\n",
    "    You emphasize the ability to explain things in a way that is accessible to all age groups.\n",
    "    Your blog posts should end with the forms -어요, -이에요/예요, -(이)여요, -(이)요.\n",
    "    \n",
    "    Hallucination\n",
    "    You always generate blog posts based on verifiable factual statements.\n",
    "    You speak mainly about factual information related to subways and do not add information about subways on your own.\n",
    "    \"\"\"\n",
    "    ),\n",
    "    # The `variable_name` here is what must align with memory\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100,memory_key=\"chat_history\", return_messages=True)\n",
    "    conversation = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=True,\n",
    "        memory=memory\n",
    "    )\n",
    "    #정보학습\n",
    "    conversation({\"question\":\"subway strike information(article) :\"+source_content+ \" Just REVIEW subway \" +category+ \" information\"})\n",
    "    #정보학습 - 체이닝 : chain_lst -> 일시, 노선, 이유\n",
    "    for i in chain_lst:\n",
    "        r=conversation({\"question\":\"Using the provided information \\n write \"+i+\":\"})\n",
    "    #글작성 - 체이닝 -> 정확성\n",
    "    conversation({\"question\":\"블로그 글 작성해줘\"})\n",
    "    conversation({\"question\":\"1. 뉴스기사의 내용을 학습해 2. 학습한 뉴스기사와 블로그글을 비교해 3.블로그 글에 틀린 정보가 있다면 수정해 뉴스기사: \"+source_content+\"블로그 글 :\"})\n",
    "    #글 작성 - 템플릿\n",
    "    result=conversation({\"question\":prompt_template})\n",
    "    memory.clear()\n",
    "    return result[\"blogtext\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e82f8e-9952-43b4-ab2c-3ed6d16d01bd",
   "metadata": {
    "id": "72e82f8e-9952-43b4-ab2c-3ed6d16d01bd"
   },
   "source": [
    "# 템플릿 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7io8mx_yoMx",
   "metadata": {
    "id": "e7io8mx_yoMx"
   },
   "source": [
    "### 📌 Metric 코드 - 키워드 & 요약문 버전 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hqhRoW8dVKWV",
   "metadata": {
    "id": "hqhRoW8dVKWV"
   },
   "outputs": [],
   "source": [
    "def evaluate_blog_metric(title, date, article, category, blog_post):\n",
    "\n",
    "    # Combine title, date, and article into a single news string\n",
    "    news = f\"\"\"<뉴스 제목>: {title},\n",
    "    <뉴스 생성일자>: {date},\n",
    "    <뉴스 본문>: {article}\"\"\"\n",
    "\n",
    "    # Determine keywords based on category\n",
    "    if category == \"지연\" or category== \"연착\" :\n",
    "        keywords = [\"지연/사고 일시\", \"지연/사고 노선\", \"지연/사고 이유\"]\n",
    "    elif category == \"파업 \":\n",
    "        keywords = [\"파업 일시\", \"파업 노선\", \"파업 이유\"]\n",
    "    else:\n",
    "        keywords = [\"시간표 변경 일시\", \"변경된 시간표\", \"변경 이유\"]\n",
    "\n",
    "    # Calculate the keyword-based metric\n",
    "    matches = sum(1 for keyword in keywords if keyword in blog_post)\n",
    "    rouge_keyword = matches / len(keywords)\n",
    "\n",
    "    # Generate summaries for reference and generated content\n",
    "    summarizer_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are talented at summarizing text without missing any important information.\"),\n",
    "        (\"user\", \"Read this article and summarize in 3-5 sentences ONLY in Korean. Article: {article}, Summary :\")\n",
    "    ])\n",
    "\n",
    "    summarize_chain = summarizer_prompt | llm | output_parser\n",
    "    reference = summarize_chain.invoke({\"article\": news})\n",
    "    generated = summarize_chain.invoke({\"article\": blog_post})\n",
    "\n",
    "    # Calculate the ROUGE score for summaries\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    rouge_summary = scorer.score(reference, generated)\n",
    "\n",
    "    return rouge_keyword, rouge_summary['rouge1'].recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "euSfI6s-yezV",
   "metadata": {
    "id": "euSfI6s-yezV"
   },
   "source": [
    "### 📌 QGQA 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CaNamsb2exwJ",
   "metadata": {
    "id": "CaNamsb2exwJ"
   },
   "outputs": [],
   "source": [
    "# QGQA를 위한 프롬프트 정의\n",
    "# PROMPT1 - 뉴스 기반 질문 생성\n",
    "qgqa_prompt_1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI trained to generate insightful questions from a given article.\"\"\"),\n",
    "    (\"user\", \"\"\"\n",
    "    1. Read the article about current Seoul subway news.\n",
    "    2. Find out what is the main incident related with subway in the article.\n",
    "    3. Find the date that this article was issued\n",
    "    4. Find every date-related expression in the article.\n",
    "    5. Compare 3 and 4, and find out the date the incident was occured.\n",
    "    6. Find every expression related to line of subway in the article.\n",
    "    7. Find out which line the incident is about.\n",
    "    8. Create 2 questions to identify the main points of the news (date of the incident, subway line of the incident). The questions should be 5-way multiple choice questions where you have to choose one of the choices from 1 to 5. One of the options must be “Unknown” and the selection for the “Date of Event” question must be in the format 2018년 3월 18일. Hint is provided with every questions\n",
    "\n",
    "    <Example Question>: 'Where did the subway incident occur? (1) Gangnam Station (2) Seongsu Station (3) Suyu Station (4) Ankguk Station (5) Unknown)',\n",
    "    <Example Hint>:''\n",
    "    News Article= {input}\n",
    "    \"\"\"),\n",
    "    (\"system\", \"\"\"Generate 2 questions. All should be in Korean ONLY.\n",
    "\n",
    "Template:\n",
    "Question1: {{}},\n",
    "Hint1: {{}},\n",
    "Question2: {{}},\n",
    "Hint2: {{}}\"\"\")\n",
    "])\n",
    "qgqa_chain_1 = qgqa_prompt_1 | llm | output_parser\n",
    "\n",
    "\n",
    "# PROMPT2 - 뉴스에 대해 답변 도출\n",
    "qgqa_prompt_2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You read a news article and answer a question accurately based on what you read.\"\"\"), # 페르소나 부여\n",
    "    (\"user\", \"\"\"\n",
    "    You read a news article like this:\n",
    "    1. Read the article about current Seoul subway news.\n",
    "    2. Find out what is the main incident related with subway in the article.\n",
    "    3. Find the date that this article was issued\n",
    "    4. Find every date-related expression in the article.\n",
    "    5. Compare 3 and 4, and find out the date the incident was occured.\n",
    "    6. Find every expression related to line of subway in the article.\n",
    "    7. Find out which line the incident is about.\n",
    "    Then you answer a question accurately based on what you read.\n",
    "    Example= “1번, 5번, 4번”,\n",
    "    news= {input}\n",
    "    Questions= {question}\n",
    "    \"\"\"),\n",
    "    (\"system\", \"\"\"\"Template(MUST FOLLOW): Answer1: {{answer_1}}번, Answer2: {{answer_2}}번\"\"\")\n",
    "])\n",
    "qgqa_chain_2 = qgqa_prompt_2 | llm | output_parser\n",
    "\n",
    "\n",
    "# PROMPT3 입력 - 블로그글에 대해 답변 도출\n",
    "qgqa_prompt_3 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You read a blog article and answer a question accurately based on what you read.\"\"\"), # 페르소나 부여\n",
    "    (\"user\", \"\"\"\n",
    "    You read a blog article like this:\n",
    "    1. Read the blog about current Seoul subway news.\n",
    "    2. Find out what is the main incident related with subway in the article.\n",
    "    3. Find the date that this article was issued\n",
    "    4. Find every date-related expression in the article.\n",
    "    5. Compare 3 and 4, and find out the date the incident was occured.\n",
    "    6. Find every expression related to line of subway in the article.\n",
    "    7. Find out which line the incident is about.\n",
    "    Then you answer a question accurately based on what you read.\n",
    "    Example= “1번, 5번, 4번”,\n",
    "    news= {input}\n",
    "    Questions= {question}\n",
    "    \"\"\"),\n",
    "    (\"system\", \"\"\"\"Template(MUST FOLLOW): Answer1: {{answer_1}}번, Answer2: {{answer_2}}번\"\"\")\n",
    "])\n",
    "qgqa_chain_3 = qgqa_prompt_3 | llm | output_parser\n",
    "\n",
    "\n",
    "# evaluate_blog_qgqa 함수 정의\n",
    "def evaluate_blog_qgqa(title, date, article, blog_post):\n",
    "\n",
    "  # news = 제목 + 날짜 + 본문\n",
    "  news = f\"\"\"<뉴스 제목>: {title},\n",
    "  <뉴스 생성일자>: {date},\n",
    "  <뉴스 본문>: {article}\"\"\"\n",
    "\n",
    "  # qgqa\n",
    "  question_list = qgqa_chain_1.invoke({\"input\": news})\n",
    "  answer_list_news = qgqa_chain_2.invoke({\"input\": news, \"question\": question_list})\n",
    "  answer_list_blog = qgqa_chain_3.invoke({\"input\": blog_post, \"question\": question_list})\n",
    "  return answer_list_news == answer_list_blog, question_list, answer_list_news, answer_list_blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZDbNUd4Oykpt",
   "metadata": {
    "id": "ZDbNUd4Oykpt"
   },
   "source": [
    "### 📌G-EVAL 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d39fa4-18db-41a6-b6ca-26884df58d5c",
   "metadata": {
    "id": "e2d39fa4-18db-41a6-b6ca-26884df58d5c"
   },
   "outputs": [],
   "source": [
    "df_eval=pd.read_csv(\"GEVAL.csv\",index_col=\"Unnamed: 0\")\n",
    "eval_dic = {'Cosistency': df_eval.iloc[0,0], 'Human_Likeness':df_eval.iloc[1,0], 'Coherence':df_eval.iloc[1,0], 'Blog':df_eval.iloc[1,0], 'Fluency':df_eval.iloc[1,0]}\n",
    "eval=[df_eval.iloc[0,0],df_eval.iloc[1,0],df_eval.iloc[2,0],df_eval.iloc[3,0],df_eval.iloc[4,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99a43e-c4ef-4bd9-a1fe-05008411bcb5",
   "metadata": {
    "id": "af99a43e-c4ef-4bd9-a1fe-05008411bcb5"
   },
   "outputs": [],
   "source": [
    "def evaluate_blog(blog_post, evaluation_prompt, source=None):\n",
    "\n",
    "    evaluation_result = \"\"\n",
    "\n",
    "    # 정확성 이외 평가 (source 필요 없음)\n",
    "    if source==None:\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", evaluation_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "        ])\n",
    "        chain=prompt|llm|output_parser\n",
    "        evaluation_result = chain.invoke({\"input\": f\"blog content: {blog_post}\"})\n",
    "\n",
    "\n",
    "    # 정확성 평가 (source 필요)\n",
    "    if source is not None:\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", evaluation_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "        ])\n",
    "        chain = prompt | llm | output_parser\n",
    "        evaluation_result=chain.invoke({\"input\": \"blog content:\"+blog_post+\"article, source:\"+source})\n",
    "    return evaluation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slZNVkosH5cr",
   "metadata": {
    "id": "slZNVkosH5cr"
   },
   "source": [
    "## 📌 평가지표 코드 병합 및 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nZP-SH7vH5DF",
   "metadata": {
    "id": "nZP-SH7vH5DF"
   },
   "outputs": [],
   "source": [
    "# 최종 평가 함수\n",
    "def evaluation_total(title, date, article, category, blog_post):\n",
    "    # news = 제목 + 날짜 + 본문\n",
    "    news = f\"\"\"<뉴스 제목>: {title},\n",
    "   <뉴스 생성일자>: {date},\n",
    "   <뉴스 본문>: {article}\"\"\"\n",
    "\n",
    "    # Step 1(메트릭)\n",
    "    metric_result = evaluate_blog_metric(title, date, article, category, blog_post)\n",
    "    if not metric_result[0] == 1:\n",
    "        return f'Fail(Metric keyword: {metric_result[0]})'\n",
    "\n",
    "    #if metric_result[1] < 0.2:\n",
    "    #    return f'Fail(Metric summary: {metric_result[0]})'\n",
    "\n",
    "    # Step 2(QGQA)\n",
    "    qgqa_result = evaluate_blog_qgqa(title, date, article, blog_post)\n",
    "    if qgqa_result[0] != True:\n",
    "        return f'''Fail(QGQA: {qgqa_result[1]},\n",
    "        {qgqa_result[2]},\n",
    "         {qgqa_result[3]})'''\n",
    "\n",
    "    # Step 3(G-EVAL)\n",
    "    scores = []\n",
    "    for i in list(eval_dic.items()):\n",
    "        if i[0] == 'Cosistency':\n",
    "            \n",
    "            score = evaluate_blog(blog_post, i[1], source=news)\n",
    "            pattern = r\"Scores\\(SCORE ONLY\\): (\\d+)\"\n",
    "            match = re.search(pattern, score)\n",
    "            if match:\n",
    "                consistency_score = int(match.group(1))\n",
    "                scores.append(consistency_score)\n",
    "            else:\n",
    "                return \"No Consistency score found.\"\n",
    "        else:\n",
    "            score = evaluate_blog(blog_post, i[1])\n",
    "            pattern = r\"Scores \\(SCORE ONLY\\): (\\d+)\"\n",
    "            match = re.search(pattern, score)\n",
    "            if match:\n",
    "                scores_score = float(match.group(1))\n",
    "                scores.append(scores_score)\n",
    "            else:\n",
    "                return \"No Scores (SCORE ONLY) score found.\"\n",
    "\n",
    "        if scores[0] <= 4:\n",
    "            return 'Fail(G-EVAL: Accuracy)'\n",
    "        if not all(score >= 3 for score in scores[1:5]):\n",
    "            return 'Fail(G-EVAL: etc)'\n",
    "\n",
    "    return True # 모든 조건 통과시 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197950b-0a7b-4371-b98d-a1cefb631bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>indexed_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.redaily.co.kr/news/articleView.htm...</td>\n",
       "      <td>[소통열차] 열차가 지연되는 65가지 이유 (9)</td>\n",
       "      <td>[]</td>\n",
       "      <td>2024-06-05 11:37:35+09:00</td>\n",
       "      <td>김성호 동양대학교 초빙교수 / 철도경제\\n\\n[철도경제신문=김성호/동양대학교 초빙교...</td>\n",
       "      <td>지연</td>\n",
       "      <td>True</td>\n",
       "      <td>1: [소통열차] 열차가 지연되는 65가지 이유 (9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.nocutnews.co.kr/news/6156202?utm_s...</td>\n",
       "      <td>청량리-신내 연결 '면목선 경전철' 예타 통과…사업추진 가속도</td>\n",
       "      <td>[Cbs노컷뉴스 장규석 기자]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>사고</td>\n",
       "      <td>True</td>\n",
       "      <td>7: 청량리-신내 연결 '면목선 경전철' 예타 통과…사업추진 가속도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://view.asiae.co.kr/article/2024060514595...</td>\n",
       "      <td>검단신도시 최중심 입지 ‘넥스티엘 애비뉴’ 주목</td>\n",
       "      <td>[]</td>\n",
       "      <td>2024-06-05 15:05:00+09:00</td>\n",
       "      <td>최근 몇 년간 분양 시장이 위축된 상황 속에서도 핵심 입지에 위치한 곳들은 여전히 ...</td>\n",
       "      <td>연장</td>\n",
       "      <td>True</td>\n",
       "      <td>11: 검단신도시 최중심 입지 ‘넥스티엘 애비뉴’ 주목</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "1   https://www.redaily.co.kr/news/articleView.htm...   \n",
       "7   https://www.nocutnews.co.kr/news/6156202?utm_s...   \n",
       "11  https://view.asiae.co.kr/article/2024060514595...   \n",
       "\n",
       "                                 title           authors  \\\n",
       "1          [소통열차] 열차가 지연되는 65가지 이유 (9)                []   \n",
       "7   청량리-신내 연결 '면목선 경전철' 예타 통과…사업추진 가속도  [Cbs노컷뉴스 장규석 기자]   \n",
       "11          검단신도시 최중심 입지 ‘넥스티엘 애비뉴’ 주목                []   \n",
       "\n",
       "                 publish_date  \\\n",
       "1   2024-06-05 11:37:35+09:00   \n",
       "7                        None   \n",
       "11  2024-06-05 15:05:00+09:00   \n",
       "\n",
       "                                                 text category  is_relevant  \\\n",
       "1   김성호 동양대학교 초빙교수 / 철도경제\\n\\n[철도경제신문=김성호/동양대학교 초빙교...       지연         True   \n",
       "7                                                 NaN       사고         True   \n",
       "11  최근 몇 년간 분양 시장이 위축된 상황 속에서도 핵심 입지에 위치한 곳들은 여전히 ...       연장         True   \n",
       "\n",
       "                            indexed_title  \n",
       "1          1: [소통열차] 열차가 지연되는 65가지 이유 (9)  \n",
       "7   7: 청량리-신내 연결 '면목선 경전철' 예타 통과…사업추진 가속도  \n",
       "11         11: 검단신도시 최중심 입지 ‘넥스티엘 애비뉴’ 주목  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ujy7K01sqF8w",
   "metadata": {
    "id": "ujy7K01sqF8w"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m article \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m category \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m blog_post \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblogtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# 최종 함수(evaluation_total) 적용 예시\n",
    "title = df['title'][1]\n",
    "date = df['publish_date'][1]\n",
    "article = df['text'][1]\n",
    "category = df['category'][1]\n",
    "blog_post = result[\"blogtext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dKR16pFUy60y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKR16pFUy60y",
    "outputId": "1e175bf0-d968-436e-9952-5a961d416faa"
   },
   "outputs": [],
   "source": [
    "evaluation_total(title, date, article, category, blog_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38066a03-e957-4d05-8c21-fc73a1dd1fa1",
   "metadata": {},
   "source": [
    "# 이미지 및 카드뉴스 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b6f75-e69a-4af1-8263-014d534a50a6",
   "metadata": {},
   "source": [
    "### 📌 정보 추출\n",
    "\n",
    "extract_info(text,category)\n",
    ": 발행된 블로그 글과 글의 주제에 따라 날짜와 노선 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a53cc-06c4-4854-9880-7cfd08ebdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(text, category):\n",
    "    # 전처리: **과 {{ }} 및 기타 기호 제거\n",
    "    cleaned_text = re.sub(r'\\*\\*', '', text)\n",
    "    cleaned_text = re.sub(r'\\{\\{|\\}\\}', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r': ', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'- ', '', cleaned_text)\n",
    "\n",
    "    if category == \"delay\":\n",
    "        # 정규 표현식을 사용하여 지연 정보 추출\n",
    "        date_pattern1 = r\"지연/사고 일시\\s*\\n\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        line_pattern1 = r\"지연/사고 노선\\s*\\n\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        date_pattern2 = r\"지연/사고 일시\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        line_pattern2 = r\"지연/사고 노선\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        date_pattern3 = r\"지연/사고 일시\\s*\\n\\s*(.+?)(?=\\n\\n|\\n\\s*{{|\\n\\s*\\*\\*|$)\"\n",
    "        line_pattern3 = r\"지연/사고 노선\\s*\\n\\s*(.+?)(?=\\n\\n|\\n\\s*{{|\\n\\s*\\*\\*|$)\"\n",
    "    elif category == \"strike\":\n",
    "        # 정규 표현식을 사용하여 파업 정보 추출\n",
    "        date_pattern1 = r\"파업 일시\\s*\\n\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        line_pattern1 = r\"파업 노선\\s*\\n\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        date_pattern2 = r\"파업 일시\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        line_pattern2 = r\"파업 노선\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        date_pattern3 = r\"파업 일시\\s*\\n\\s*(.+?)(?=\\n\\n|\\n\\s*{{|\\n\\s*\\*\\*|$)\"\n",
    "        line_pattern3 = r\"파업 노선\\s*\\n\\s*(.+?)(?=\\n\\n|\\n\\s*{{|\\n\\s*\\*\\*|$)\"\n",
    "    else:\n",
    "        date_pattern1 = r\"변경 일시\\s*\\n\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        line_pattern1 = r\"변경 노선\\s*\\n\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        date_pattern2 = r\"변경 일시\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        line_pattern2 = r\"변경 노선\\s*(.+?)(?:\\r?\\n|$)\"\n",
    "        date_pattern3 = r\"변경 일시\\s*\\n\\s*(.+?)(?=\\n\\n|\\n\\s*{{|\\n\\s*\\*\\*|$)\"\n",
    "        line_pattern3 = r\"변경 노선\\s*\\n\\s*(.+?)(?=\\n\\n|\\n\\s*{{|\\n\\s*\\*\\*|$)\"\n",
    "\n",
    "    # 일시 추출\n",
    "    date_match3 = re.search(date_pattern3, cleaned_text, re.DOTALL)\n",
    "    if date_match3:\n",
    "        dates = [date.strip() for date in date_match3.group(1).split('\\n')]\n",
    "    else:\n",
    "        date_match1 = re.search(date_pattern1, cleaned_text)\n",
    "        date_match2 = re.search(date_pattern2, cleaned_text)\n",
    "        if date_match1:\n",
    "            dates = [date_match1.group(1)]\n",
    "        elif date_match2:\n",
    "            dates = [date_match2.group(1)]\n",
    "        else:\n",
    "            dates = [\"날짜 정보 없음\"]\n",
    "    \n",
    "    # 노선 추출\n",
    "    line_match3 = re.search(line_pattern3, cleaned_text, re.DOTALL)\n",
    "    if line_match3:\n",
    "        lines = [line.strip() for line in line_match3.group(1).split('\\n')]\n",
    "    else:\n",
    "        line_match1 = re.search(line_pattern1, cleaned_text)\n",
    "        line_match2 = re.search(line_pattern2, cleaned_text)\n",
    "        if line_match1:\n",
    "            lines = [line_match1.group(1)]\n",
    "        elif line_match2:\n",
    "            lines = [line_match2.group(1)]\n",
    "        else:\n",
    "            lines = [\"노선 정보 없음\"]\n",
    "\n",
    "    # 리스트를 단일 문자열로 변환\n",
    "    dates_str = ', '.join(dates)\n",
    "    lines_str = ', '.join(lines)\n",
    "\n",
    "    # 정보를 딕셔너리로 저장\n",
    "    info = {\n",
    "        \"date\": dates_str,\n",
    "        \"line\": lines_str\n",
    "    }\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79530996-69ea-489d-b249-4774fe9ca2b0",
   "metadata": {},
   "source": [
    "### 📌 카드뉴스 생성\n",
    "- create_card_news(info,category) : 추출된 정보를 이용해 카드뉴스 생성\n",
    "- make_card_news(text,category) : 정보 추출 및 카드뉴슷 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c09a33-ae15-47db-81eb-e85fc598eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_card_news(info,category, width=1080, height=1080):\n",
    "    # 배경 이미지 로드\n",
    "    image_path = '이미지생성/지통이최종.png'  # 이미지 경로 설정\n",
    "    image = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "\n",
    "    # 폰트 설정\n",
    "    font_path = \"NanumSquareRoundOTFEB.otf\"  # 폰트 경로를 적절하게 설정하세요\n",
    "    title_font = ImageFont.truetype(font_path, 500)\n",
    "    tail_font = ImageFont.truetype(font_path, 100)\n",
    "\n",
    "\n",
    "    # content_font 크기 동적 설정\n",
    "    content_text_length = max(len(info['date']), len(info['line']))\n",
    "    print(content_text_length)\n",
    "    if content_text_length >= 23:\n",
    "        content_font_size = 150\n",
    "    elif 19 <= content_text_length < 23:\n",
    "        content_font_size = 180\n",
    "    elif 10 <= content_text_length < 19:\n",
    "        content_font_size = 300\n",
    "    else:\n",
    "        content_font_size = 400\n",
    "        \n",
    "    content_font = ImageFont.truetype(font_path, content_font_size)\n",
    "\n",
    "\n",
    "    # 텍스트 그리는 함수\n",
    "    def draw_text(x, y, text, font, fill=\"Black\"):\n",
    "        # 텍스트 박스 크기 측정\n",
    "        text_width, text_height = draw.textbbox((0, 0), text, font=font)[2:]\n",
    "        # 텍스트 그리기, x 위치를 중앙 조정\n",
    "        draw.text((x - text_width / 2, y - text_height / 2), text, font=font, fill=fill)\n",
    "\n",
    "    # 제목과 내용 텍스트 위치\n",
    "    title_text = {\"delay\": \"지하철 지연\", \"strike\": \"지하철 파업\", \"timetable\": \"시간표 변경\"}.get(category, \"정보\")\n",
    "    draw_text(width / 2, height * 0.2, title_text, title_font, fill=\"White\")\n",
    "    draw_text(width / 2, height * 0.55, info['date'], content_font, fill=\"Red\")\n",
    "    draw_text(width / 2, height * 0.75, info['line'], content_font, fill=\"Red\")\n",
    "    draw_text(width / 2, height * 0.925, '오늘의 지하철 소식통', tail_font, fill=\"White\")\n",
    "\n",
    "    # 텍스트 그리는 함수\n",
    "    def draw_text(x, y, text, font, fill=\"White\"):\n",
    "        # 텍스트 박스 크기 측정\n",
    "        text_width, text_height = draw.textbbox((0, 0), text, font=font)[2:]\n",
    "        # 텍스트 그리기, x 위치를 중앙 조정\n",
    "        draw.text((x - text_width / 2, y - text_height / 2), text, font=font, fill=fill)\n",
    "\n",
    "    # 날짜 정보를 파일 이름으로 사용할 수 있는 형식으로 변환\n",
    "    date_str = info['date'].replace(' ', '')\n",
    "\n",
    "    # 이미지 저장 경로 설정 및 보기\n",
    "    save_path = f\"이미지생성/{category}_{date_str}_info.png\"\n",
    "    image.save(save_path)\n",
    "    image.show()\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c818dd1-c1b9-40a1-ae61-09badcf8847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정보 추출 후 카드뉴스 생성\n",
    "def make_card_news(text,category):\n",
    "    info = extract_info(text,category)\n",
    "    create_card_news(info,category)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68e5a3-1d18-4c76-b68e-1ea96785235d",
   "metadata": {},
   "source": [
    "### 📌 이미지 생성\n",
    "generate_image : dalle-3를 이용한 긴 글 이미지 생성\n",
    "- 프롬프트 \n",
    "1. 이미지 형식 : 사진 또는 만화\n",
    "2. 문자 없이 생성\n",
    "3. 배경은 한국\n",
    "4. 인간에게 위협을 가하는 사진은 묘사 금지\n",
    "5. 잔인하거나 해로운 장면은 묘사 금지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c60358-f2c0-44ba-9830-7286c861d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client= openai.OpenAI(api_key='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f131e019-bcba-4d64-a021-da09a4077117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(text, category, date, save_directory=\"이미지생성\"):\n",
    "    # 이미지 생성을 위한 프롬프트 설정\n",
    "    prompt = f\"\"\"\n",
    "            Create an image that looks like a real photograph or in a cartoon style based on the text you read.\n",
    "            The image should not contain any numbers, letters, text, symbols, or characters. \n",
    "            All scenarios depicted occurred in South Korea. \n",
    "            The image should not depict any scenarios where humans are harmed, threatened, or have their bodies altered in any way. \n",
    "            Additionally, the image should not be grotesque or depict anything hateful or offensive: {text}\n",
    "            \"\"\"\n",
    "    # 이미지 생성 요청\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "\n",
    "    # 생성된 이미지의 URL 출력\n",
    "    image_url = response.data[0].url\n",
    "    print(image_url)\n",
    "\n",
    "    # 날짜 정보에서 공백 제거\n",
    "    date_str = date.replace(' ', '')\n",
    "\n",
    "    # 이미지 저장 경로 설정\n",
    "    save_path = f\"{save_directory}/{category}_{date_str}_image.png\"\n",
    "\n",
    "    # 이미지 다운로드 및 저장\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=128):\n",
    "                file.write(chunk)\n",
    "        print(f\"이미지 다운로드 완료: {save_path}\")\n",
    "    else:\n",
    "        print(f\"이미지 다운로드 실패. HTTP 상태코드: {response.status_code}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9ae4d-018a-44c5-8139-2fdaa1cb2678",
   "metadata": {},
   "source": [
    "## 📌 최종 평가 후 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c2de4-8faa-4ec5-93c8-b14e44719a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 평가 후 이미지 및 카드 뉴스 생성 함수\n",
    "def evaluate_and_create_image(title, date, article, category, blog_post):\n",
    "    result = evaluation_total(title, date, article, category, blog_post)\n",
    "    if result == True :\n",
    "        generate_image(blog_post,category,date)\n",
    "        make_card_news(blog_post, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637c3b8-72f9-4c89-bca5-142e007fbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_and_create_image 적용 예시\n",
    "title = '\"인천지하철서 20대 응급환자…시민·공사 직원 합심해 구해'\n",
    "date = '2024.05.30 14:12'\n",
    "article = \"\"\"인천지하철 1호선 객실에서 응급 환자가 발생했지만, 시민과 인천교통공사의 신속한 조치로 소중한 생명을 구했습니다.\n",
    "\n",
    "그제(28일) 밤 10시 9분쯤 인천교통공사 종합관제실 직원 김성준 씨는 인천1호선 동수역 승강장에 도착한 열차 기관사로부터 객실 안에서 20대 남성 응급환자가 발생했다는 긴박한 연락을 받았습니다.\n",
    "\n",
    "김 관제사는 즉시 동수역 직원에게 구급장비를 갖고 정차 중인 열차에 출동해 환자를 구하도록 지시했고 때마침 해당 열차 객실에 타고 있던 30대 여성 간호사가 안내방송을 듣고 해당 칸으로 이동해 쓰러져있는 환자에게 심폐소생술을 실시했습니다.\n",
    "\n",
    "이후 도착한 역 직원과 함께 자동제세동기(AED)를 사용해 응급조치를 실시했지만, 이후에도 상황이 위중하다고 판단해 환자를 승강장으로 이동시키지 않고 열차 안에서 환자 상태를 계속 살폈습니다.\n",
    "\n",
    "이후 119구급대가 도착해 해당 환자를 병원으로 즉시 이송해 생명을 구했습니다.\n",
    "\n",
    "인천교통공사는 응급환자에 대한 조치로 13분가량 열차가 지연됐지만, 안내방송과 승객들의 협조로 이와 관련해 단 한 건의 민원도 발생하지 않았다고 밝혔습니다.\n",
    "\n",
    "인천 1, 2, 7호선 모든 역사에는 자동제세동기(AED)가 설치돼 있습니다.\n",
    "\n",
    "인천교통공사는 승객의 생명을 구하는데 가장 큰 공을 세우고 홀연히 떠난 시민을 찾아서 감사패를 전달할 예정입니다.\n",
    "\"\"\" # 본문\n",
    "category = 'delay'\n",
    "blog_post = \"\"\"\n",
    "**영웅들이 함께 만든 기적, 인천 지하철의 감동적인 이야기**\n",
    "\n",
    "안녕하세요, 여러분의 출퇴근 메신저 지하철 온다의 '오.지.통 [오늘의 지하철 소식통]' 인사 드립니다!\n",
    "\n",
    "**지연/사고 일시**\n",
    "2024년 5월 28일 오후 10시 09분\n",
    "\n",
    "**지연/사고 노선**\n",
    "인천 1호선\n",
    "\n",
    "**지연/사고 이유**\n",
    "응급 환자 발생\n",
    "\n",
    "**문의 사항 링크**\n",
    "[인천교통공사 고객센터](https://www.ictr.or.kr/kr/customerService/customerService)\n",
    "\n",
    "---\n",
    "\n",
    "안녕하세요, 지하철 이용자 여러분! 오늘은 인천 지하철에서 일어난 감동적인 소식을 전해드리려고 해요. 바로 우리 모두가 히어로가 될 수 있는 순간을 보여준 이야기랍니다.\n",
    "\n",
    "2024년 5월 28일 저녁 10시 09분, 인천 1호선을 타고 가던 중 한 20대 승객이 갑작스러운 응급 상황에 처하게 되었어요. 이때 승객들은 모두가 한마음이 되어 신속하게 대처했답니다. 특히 현장에 있던 한 간호사분이 바로 심폐소생술을 시작했고, 인천교통공사 직원들이 AED(자동 심장 충격기)를 사용하여 환자의 생명을 구했어요.\n",
    "\n",
    "이 덕분에 환자는 무사히 병원으로 이송될 수 있었고, 전철은 13분 정도 지연되었지만, 아무도 불평하지 않았어요. 오히려 모든 승객들이 한마음으로 응원하고 지지하는 모습이 정말 인상적이었어요. 인천교통공사에서도 이번 일에 도움을 준 시민에게 감사의 뜻을 전할 예정이라고 해요.\n",
    "\n",
    "이 사건을 통해 다시 한번 느낀 것은, 우리 모두가 조금만 관심을 가지고 배려하면 큰 기적을 만들 수 있다는 점이에요. 지하철을 이용하는 동안, 우리 주변에 무슨 일이 일어나고 있는지 한 번 더 살펴보는 것도 중요한 것 같아요.\n",
    "\n",
    "---\n",
    "\n",
    "오지통이 실시간으로 다양한 지하철 정보를 업데이트할 예정이니, 자주 방문해 주세요.\n",
    "'지하철 온다'는 단 한 번의 터치로 자신의 위치에서 가장 가까운 지하철 역의 실시간 정보를 제공합니다.\n",
    "\n",
    "🔽 지하철 온다 소개 보러가기\n",
    "[지하철 온다 블로그](https://blog.naver.com/subway__onda/223258646349)\n",
    "\n",
    "지하철 파업으로 아침마다 출근하기 힘드네요, 그렇죠? 그래도 모두 힘내서 파이팅해요!\n",
    "\n",
    "여러분의 안전과 편안한 지하철 이용을 위해 항상 노력하는 오.지.통이었어요. 다음에 또 만나요!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a9da6-34d4-430c-8b94-4b8db86af02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_create_image(title, date, article, category, blog_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d0461-d5fe-458b-b039-84f56017e6f8",
   "metadata": {},
   "source": [
    "# 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ad58c-f61e-40e1-88cd-3828a1872c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = title + date + article\n",
    "blog_post = text_generation(input,category)\n",
    "evaluate_and_create_image(title, date, article, category, blog_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec580e-5eec-40e6-ad3f-dfed4de28821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_and_create_image(title, date, article, category, blog_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850b0d5-55a2-4240-8e11-de0c0c74aa22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
